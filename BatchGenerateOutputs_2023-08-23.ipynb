{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Optional, Union, Callable\n",
    "import tables as tb\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "from attrs import define, field, Factory\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "import pyphoplacecellanalysis.General.Batch.runBatch\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "BATCH_DATE_TO_USE = '2023-08-22' # used for filenames throught the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef5938c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/global_batch_result_2023-08-22.pkl... done.\n",
      "Failure loading /nfs/turbo/umms-kdiba/Data/global_batch_result_2023-08-22.pkl.\n",
      "creating new batch_run\n",
      "local_session_names_list: ['2006-6-07_11-26-53', '2006-6-08_14-26-15', '2006-6-09_1-22-43', '2006-6-09_3-23-37', '2006-6-12_15-55-31', '2006-6-13_14-42-6']\n",
      "local_session_names_list: ['2006-6-07_16-40-19', '2006-6-08_15-46-47', '2006-6-08_21-16-25', '2006-6-09_22-24-40', '2006-6-12_16-53-46', '2006-6-13_15-22-3']\n",
      "local_session_names_list: ['2006-4-09_17-29-30', '2006-4-10_12-25-50', '2006-4-10_21-2-40', '2006-4-11_15-16-59', '2006-4-12_14-39-31', '2006-4-12_17-53-55', '2006-4-16_15-12-23', '2006-4-17_12-33-47', '2006-4-18_13-6-1', '2006-4-18_15-23-32', '2006-4-19_13-34-40', '2006-4-19_16-48-9', '2006-4-21_10-24-35', '2006-4-25_14-28-51', '2006-4-25_17-17-6', '2006-4-26_13-22-13', '2006-4-27_14-43-12', '2006-4-28_12-17-27', '2006-4-28_16-48-29']\n",
      "local_session_names_list: ['2006-4-09_16-40-54', '2006-4-10_12-58-3', '2006-4-10_19-11-57', '2006-4-11_12-48-38', '2006-4-11_16-2-46', '2006-4-12_14-59-23', '2006-4-12_15-25-59', '2006-4-16_14-49-24', '2006-4-16_18-47-52', '2006-4-17_12-52-15', '2006-4-18_13-28-57', '2006-4-18_15-38-2', '2006-4-19_13-50-7', '2006-4-19_16-37-40', '2006-4-21_11-19-2', '2006-4-25_13-20-55', '2006-4-25_17-33-28', '2006-4-26_13-51-50', '2006-4-27_18-21-57', '2006-4-28_12-38-13', '2006-4-28_17-6-14']\n",
      "local_session_names_list: ['11-02_17-46-44', '11-02_19-28-0', '11-03_12-3-25', '11-03_21-26-8', '11-05_19-26-43', '11-09_11-43-50', '11-09_12-15-3', '11-09_21-17-16', '11-09_22-4-5', '11-19_12-35-59', '11-19_13-2-0', '11-19_13-55-7', 'fet11-01_12-58-54', 'fet11-03_11-0-53', 'fet11-03_20-28-3', 'fet11-04_21-20-3', 'redundant', 'showclus', 'sleep', 'tmaze']\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/global_batch_result_2023-08-22.pkl... done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>context</th>\n",
       "      <th>basedirs</th>\n",
       "      <th>status</th>\n",
       "      <th>errors</th>\n",
       "      <th>n_long_laps</th>\n",
       "      <th>n_long_replays</th>\n",
       "      <th>n_short_laps</th>\n",
       "      <th>n_short_replays</th>\n",
       "      <th>is_ready</th>\n",
       "      <th>global_computation_result_file</th>\n",
       "      <th>loaded_session_pickle_file</th>\n",
       "      <th>ripple_result_file</th>\n",
       "      <th>has_user_replay_annotations</th>\n",
       "      <th>has_user_grid_bin_bounds_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-07_11-26-53</td>\n",
       "      <td>kdiba_gor01_one_2006-6-07_11-26-53</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_3-23-37</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_3-23-37</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-04_21-20-3</td>\n",
       "      <td>kdiba_pin01_one_fet11-04_21-20-3</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>redundant</td>\n",
       "      <td>kdiba_pin01_one_redundant</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/red...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>showclus</td>\n",
       "      <td>kdiba_pin01_one_showclus</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sho...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>sleep</td>\n",
       "      <td>kdiba_pin01_one_sleep</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sleep</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>tmaze</td>\n",
       "      <td>kdiba_pin01_one_tmaze</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/tmaze</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_name animal exper_name        session_name  \\\n",
       "0        kdiba  gor01        one  2006-6-07_11-26-53   \n",
       "1        kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "2        kdiba  gor01        one   2006-6-09_1-22-43   \n",
       "3        kdiba  gor01        one   2006-6-09_3-23-37   \n",
       "4        kdiba  gor01        one  2006-6-12_15-55-31   \n",
       "..         ...    ...        ...                 ...   \n",
       "67       kdiba  pin01        one    fet11-04_21-20-3   \n",
       "68       kdiba  pin01        one           redundant   \n",
       "69       kdiba  pin01        one            showclus   \n",
       "70       kdiba  pin01        one               sleep   \n",
       "71       kdiba  pin01        one               tmaze   \n",
       "\n",
       "                               context  \\\n",
       "0   kdiba_gor01_one_2006-6-07_11-26-53   \n",
       "1   kdiba_gor01_one_2006-6-08_14-26-15   \n",
       "2    kdiba_gor01_one_2006-6-09_1-22-43   \n",
       "3    kdiba_gor01_one_2006-6-09_3-23-37   \n",
       "4   kdiba_gor01_one_2006-6-12_15-55-31   \n",
       "..                                 ...   \n",
       "67    kdiba_pin01_one_fet11-04_21-20-3   \n",
       "68           kdiba_pin01_one_redundant   \n",
       "69            kdiba_pin01_one_showclus   \n",
       "70               kdiba_pin01_one_sleep   \n",
       "71               kdiba_pin01_one_tmaze   \n",
       "\n",
       "                                             basedirs  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/red...   \n",
       "69  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sho...   \n",
       "70   /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sleep   \n",
       "71   /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/tmaze   \n",
       "\n",
       "                              status errors  n_long_laps  n_long_replays  \\\n",
       "0   SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "1   SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "2   SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "3   SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "4   SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "..                               ...    ...          ...             ...   \n",
       "67  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "68  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "69  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "70  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "71  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "\n",
       "    n_short_laps  n_short_replays  is_ready  \\\n",
       "0              0                0     False   \n",
       "1              0                0     False   \n",
       "2              0                0     False   \n",
       "3              0                0     False   \n",
       "4              0                0     False   \n",
       "..           ...              ...       ...   \n",
       "67             0                0     False   \n",
       "68             0                0     False   \n",
       "69             0                0     False   \n",
       "70             0                0     False   \n",
       "71             0                0     False   \n",
       "\n",
       "                       global_computation_result_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3                                                       \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                           loaded_session_pickle_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3                                                       \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                                   ripple_result_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \n",
       "0                         False                                  True  \n",
       "1                          True                                  True  \n",
       "2                          True                                  True  \n",
       "3                         False                                  True  \n",
       "4                          True                                  True  \n",
       "..                          ...                                   ...  \n",
       "67                        False                                  True  \n",
       "68                        False                                 False  \n",
       "69                        False                                 False  \n",
       "70                        False                                 False  \n",
       "71                        False                                 False  \n",
       "\n",
       "[72 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# active_global_batch_result_filename='global_batch_result_2023-07-12.pkl'\n",
    "# active_global_batch_result_filename='global_batch_result_2023-07-07.pkl'\n",
    "# active_global_batch_result_filename='global_batch_result_2023-07-07_extra.pkl'\n",
    "# active_global_batch_result_filename='global_batch_result_2023-07-20.pkl'\n",
    "# active_global_batch_result_filename='global_batch_result_2023-07-21_Greatlakes.pkl'\n",
    "active_global_batch_result_filename=f'global_batch_result_{BATCH_DATE_TO_USE}.pkl'\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/nfs/turbo/umms-kdiba/Data')]\n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "## Build Pickle Path:\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(active_global_batch_result_filename).resolve() # Use Default\n",
    "\n",
    "# try to load an existing batch result:\n",
    "# with set_posix_windows():\n",
    "global_batch_run = BatchRun.try_init_from_file(global_data_root_parent_path, active_global_batch_result_filename=active_global_batch_result_filename,\n",
    "\t\t\t\t\t\tskip_root_path_conversion=False, debug_print=debug_print) # on_needs_create_callback_fn=run_diba_batch\n",
    "\n",
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "batch_progress_df\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     # display(batch_progress_df)\n",
    "#     # display(good_only_batch_progress_df)\n",
    "#     display(batch_progress_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab824348",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Batch Executions/Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019afbbd-70d2-4e75-9548-b6f22d2e31ca",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>context</th>\n",
       "      <th>basedirs</th>\n",
       "      <th>status</th>\n",
       "      <th>errors</th>\n",
       "      <th>n_long_laps</th>\n",
       "      <th>n_long_replays</th>\n",
       "      <th>n_short_laps</th>\n",
       "      <th>n_short_replays</th>\n",
       "      <th>is_ready</th>\n",
       "      <th>global_computation_result_file</th>\n",
       "      <th>loaded_session_pickle_file</th>\n",
       "      <th>ripple_result_file</th>\n",
       "      <th>has_user_replay_annotations</th>\n",
       "      <th>has_user_grid_bin_bounds_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-07_16-40-19</td>\n",
       "      <td>kdiba_gor01_two_2006-6-07_16-40-19</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-08_21-16-25</td>\n",
       "      <td>kdiba_gor01_two_2006-6-08_21-16-25</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-09_22-24-40</td>\n",
       "      <td>kdiba_gor01_two_2006-6-09_22-24-40</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-12_16-53-46</td>\n",
       "      <td>kdiba_gor01_two_2006-6-12_16-53-46</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-4-09_17-29-30</td>\n",
       "      <td>kdiba_vvp01_one_2006-4-09_17-29-30</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-4-10_12-25-50</td>\n",
       "      <td>kdiba_vvp01_one_2006-4-10_12-25-50</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-4-09_16-40-54</td>\n",
       "      <td>kdiba_vvp01_two_2006-4-09_16-40-54</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-4-10_12-58-3</td>\n",
       "      <td>kdiba_vvp01_two_2006-4-10_12-58-3</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-02_17-46-44</td>\n",
       "      <td>kdiba_pin01_one_11-02_17-46-44</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-02_19-28-0</td>\n",
       "      <td>kdiba_pin01_one_11-02_19-28-0</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-03_12-3-25</td>\n",
       "      <td>kdiba_pin01_one_11-03_12-3-25</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>kdiba_pin01_one_fet11-01_12-58-54</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_name animal exper_name        session_name  \\\n",
       "1        kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "2        kdiba  gor01        one   2006-6-09_1-22-43   \n",
       "4        kdiba  gor01        one  2006-6-12_15-55-31   \n",
       "6        kdiba  gor01        two  2006-6-07_16-40-19   \n",
       "8        kdiba  gor01        two  2006-6-08_21-16-25   \n",
       "9        kdiba  gor01        two  2006-6-09_22-24-40   \n",
       "10       kdiba  gor01        two  2006-6-12_16-53-46   \n",
       "12       kdiba  vvp01        one  2006-4-09_17-29-30   \n",
       "13       kdiba  vvp01        one  2006-4-10_12-25-50   \n",
       "31       kdiba  vvp01        two  2006-4-09_16-40-54   \n",
       "32       kdiba  vvp01        two   2006-4-10_12-58-3   \n",
       "52       kdiba  pin01        one      11-02_17-46-44   \n",
       "53       kdiba  pin01        one       11-02_19-28-0   \n",
       "54       kdiba  pin01        one       11-03_12-3-25   \n",
       "64       kdiba  pin01        one   fet11-01_12-58-54   \n",
       "\n",
       "                               context  \\\n",
       "1   kdiba_gor01_one_2006-6-08_14-26-15   \n",
       "2    kdiba_gor01_one_2006-6-09_1-22-43   \n",
       "4   kdiba_gor01_one_2006-6-12_15-55-31   \n",
       "6   kdiba_gor01_two_2006-6-07_16-40-19   \n",
       "8   kdiba_gor01_two_2006-6-08_21-16-25   \n",
       "9   kdiba_gor01_two_2006-6-09_22-24-40   \n",
       "10  kdiba_gor01_two_2006-6-12_16-53-46   \n",
       "12  kdiba_vvp01_one_2006-4-09_17-29-30   \n",
       "13  kdiba_vvp01_one_2006-4-10_12-25-50   \n",
       "31  kdiba_vvp01_two_2006-4-09_16-40-54   \n",
       "32   kdiba_vvp01_two_2006-4-10_12-58-3   \n",
       "52      kdiba_pin01_one_11-02_17-46-44   \n",
       "53       kdiba_pin01_one_11-02_19-28-0   \n",
       "54       kdiba_pin01_one_11-03_12-3-25   \n",
       "64   kdiba_pin01_one_fet11-01_12-58-54   \n",
       "\n",
       "                                             basedirs  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "                              status errors  n_long_laps  n_long_replays  \\\n",
       "1   SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "2   SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "4   SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "6   SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "8   SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "9   SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "10  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "12  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "13  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "31  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "32  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "52  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "53  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "54  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "64  SessionBatchProgress.NOT_STARTED   None            0               0   \n",
       "\n",
       "    n_short_laps  n_short_replays  is_ready  \\\n",
       "1              0                0     False   \n",
       "2              0                0     False   \n",
       "4              0                0     False   \n",
       "6              0                0     False   \n",
       "8              0                0     False   \n",
       "9              0                0     False   \n",
       "10             0                0     False   \n",
       "12             0                0     False   \n",
       "13             0                0     False   \n",
       "31             0                0     False   \n",
       "32             0                0     False   \n",
       "52             0                0     False   \n",
       "53             0                0     False   \n",
       "54             0                0     False   \n",
       "64             0                0     False   \n",
       "\n",
       "                       global_computation_result_file  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "                           loaded_session_pickle_file  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "                                   ripple_result_file  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \n",
       "1                          True                                  True  \n",
       "2                          True                                  True  \n",
       "4                          True                                  True  \n",
       "6                          True                                  True  \n",
       "8                          True                                  True  \n",
       "9                          True                                  True  \n",
       "10                         True                                  True  \n",
       "12                         True                                  True  \n",
       "13                         True                                  True  \n",
       "31                         True                                  True  \n",
       "32                         True                                  True  \n",
       "52                         True                                  True  \n",
       "53                         True                                  True  \n",
       "54                         True                                  True  \n",
       "64                         True                                  True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = [\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # Bad?\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54')]\n",
    "\n",
    "batch_progress_df[np.isin(batch_progress_df['context'].values, included_session_contexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "import tables as tb\n",
    "from copy import deepcopy\n",
    "from neuropy.core import Epoch\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler\n",
    "\n",
    "@define(slots=False, repr=False)\n",
    "class HDFSpecificBatchSessionCompletionHandler(BatchSessionCompletionHandler):\n",
    "    \"\"\" handles completion of a single session's batch processing. \n",
    "\n",
    "    Allows accumulating results across sessions and runs.\n",
    "\n",
    "    \n",
    "    Usage:\n",
    "        from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Completion Result object returned from callback ____________________________________________________________________ #\n",
    " \n",
    "    # Cross-session Results:\n",
    "    across_sessions_instantaneous_fr_dict: dict = Factory(dict) # Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "    ## Main function that's called with the complete pipeline:\n",
    "    def on_complete_success_execution_session(self, global_data_root_parent_path, curr_session_context, curr_session_basedir, curr_active_pipeline) -> PipelineCompletionResult:\n",
    "        \"\"\" called when the execute_session completes like:\n",
    "            `post_run_callback_fn_output = post_run_callback_fn(curr_session_context, curr_session_basedir, curr_active_pipeline)`\n",
    "            \n",
    "            Meant to be assigned like:\n",
    "            , post_run_callback_fn=_on_complete_success_execution_session\n",
    "            \n",
    "            Captures nothing.\n",
    "            \n",
    "            from Spike3D.scripts.run_BatchAnalysis import _on_complete_success_execution_session\n",
    "            \n",
    "            \n",
    "            LOGIC: really we want to recompute global whenever local is recomputed.\n",
    "            \n",
    "            \n",
    "        \"\"\"\n",
    "        print(f'HDFProcessing.on_complete_success_execution_session(curr_session_context: {curr_session_context}, curr_session_basedir: {str(curr_session_basedir)}, ...)')\n",
    "        # print(f'curr_session_context: {curr_session_context}, curr_session_basedir: {str(curr_session_basedir)}')\n",
    "        long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "        # long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "        # long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\n",
    "        # Get existing laps from session:\n",
    "        long_laps, short_laps, global_laps = [curr_active_pipeline.filtered_sessions[an_epoch_name].laps.as_epoch_obj() for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "        long_replays, short_replays, global_replays = [Epoch(curr_active_pipeline.filtered_sessions[an_epoch_name].replay.epochs.get_valid_df()) for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "        # short_laps.n_epochs: 40, n_long_laps.n_epochs: 40\n",
    "        # short_replays.n_epochs: 6, long_replays.n_epochs: 8\n",
    "        if self.debug_print:\n",
    "            print(f'short_laps.n_epochs: {short_laps.n_epochs}, n_long_laps.n_epochs: {long_laps.n_epochs}')\n",
    "            print(f'short_replays.n_epochs: {short_replays.n_epochs}, long_replays.n_epochs: {long_replays.n_epochs}')\n",
    "\n",
    "        # ## Post Compute Validate 2023-05-16:\n",
    "        try:\n",
    "            was_updated = self.post_compute_validate(curr_active_pipeline)\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            an_err = CapturedException(e, exception_info)\n",
    "            print(f'self.post_compute_validate(...) failed with exception: {an_err}')\n",
    "            raise \n",
    "\n",
    "        delta_since_last_compute: timedelta = curr_active_pipeline.get_time_since_last_computation()\n",
    "        print(f'\\t time since last computation: {delta_since_last_compute}')\n",
    "        \n",
    "        ## Save the pipeline since that's disabled by default now:\n",
    "        try:\n",
    "            curr_active_pipeline.save_pipeline(saving_mode=self.saving_mode, active_pickle_filename=self.override_session_computation_results_pickle_filename) # AttributeError: 'PfND_TimeDependent' object has no attribute '_included_thresh_neurons_indx'\n",
    "        except Exception as e:\n",
    "            ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'ERROR SAVING PIPELINE for curr_session_context: {curr_session_context}. error: {e}')\n",
    "\n",
    "\n",
    "        ## GLOBAL FUNCTION:\n",
    "        if self.force_reload_all and (not self.force_global_recompute):\n",
    "            print(f'WARNING: self.force_global_recompute was False but self.force_reload_all was true. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.')\n",
    "            self.force_global_recompute = True\n",
    "            \n",
    "        if was_updated and (not self.force_global_recompute):\n",
    "            print(f'WARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.')\n",
    "            self.force_global_recompute = True\n",
    "\n",
    "\n",
    "        ## GLOBAL FUNCTION:\n",
    "        if self.force_reload_all and (not self.force_global_recompute):\n",
    "            print(f'WARNING: self.force_global_recompute was False but self.force_reload_all was true. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.')\n",
    "            self.force_global_recompute = True\n",
    "            \n",
    "        if was_updated and (not self.force_global_recompute):\n",
    "            print(f'WARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.')\n",
    "            self.force_global_recompute = True\n",
    "\n",
    "        self.try_compute_global_computations_if_needed(curr_active_pipeline, curr_session_context=curr_session_context)\n",
    "\n",
    "        ### Aggregate Outputs specific computations:\n",
    "\n",
    "        ## Get some more interesting session properties:\n",
    "        \n",
    "        delta_since_last_compute: timedelta = curr_active_pipeline.get_time_since_last_computation()\n",
    "        \n",
    "        print(f'\\t time since last computation: {delta_since_last_compute}')\n",
    "\n",
    "        # Export the pipeline's HDF5:\n",
    "        hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('pipeline_results.h5').resolve()\n",
    "        ## Check the typical HDF5 output path and see if one already exists there:\n",
    "        print(f'pipeline hdf5_output_path: {hdf5_output_path}')\n",
    "        try:\n",
    "            AcrossSessionsResults.build_session_pipeline_to_hdf(hdf5_output_path, \"/\", curr_active_pipeline, debug_print=False) # coulduse key of \"/{curr_session_context}\" with context properly expanded.\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f\"ERROR: encountered exception {e} while trying to build the session HDF output for {curr_session_context}\")\n",
    "            hdf5_output_path = None # set to None because it failed.\n",
    "            \n",
    "\n",
    "        # print(f'\\t doing specific instantaneous firing rate computation for context: {curr_session_context}...')\n",
    "        # ## Specify the output file:\n",
    "        # common_file_path = Path('output/active_across_session_scatter_plot_results.h5')\n",
    "        # print(f'common_file_path: {common_file_path}')\n",
    "        # InstantaneousFiringRatesDataframeAccessor.add_results_to_inst_fr_results_table(curr_active_pipeline, common_file_path, file_mode='a')\n",
    "        \n",
    "        across_session_results_extended_dict = {}\n",
    "            \n",
    "        return PipelineCompletionResult(long_epoch_name=long_epoch_name, long_laps=long_laps, long_replays=long_replays,\n",
    "                                           short_epoch_name=short_epoch_name, short_laps=short_laps, short_replays=short_replays,\n",
    "                                           delta_since_last_compute=delta_since_last_compute,\n",
    "                                           outputs_local={'pkl': curr_active_pipeline.pickle_path},\n",
    "                                            outputs_global={'pkl': curr_active_pipeline.global_computation_results_pickle_path, 'hdf5': hdf5_output_path},\n",
    "                                            across_session_results=across_session_results_extended_dict)\n",
    "                                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "629c5dda",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(included_session_contexts): 15\n",
      "Beginning processing with len(included_session_contexts): 15\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_gor01_one_2006-6-08_14-26-15\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.spikes.mat... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/NeuroPy/neuropy/core/session/Formats/SessionSpecifications.py:122: UserWarning: WARNING: Optional File: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.dat does not exist. Continuing without it.\n",
      "  warnings.warn(f'WARNING: Optional File: {an_optional_filepath} does not exist. Continuing without it.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position.npy... 2006-6-08_14-26-15.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.interpolated_spike_positions.npy... 2006-6-08_14-26-15.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.mua.npy... 2006-6-08_14-26-15.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.pbe.npy... 2006-6-08_14-26-15.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 503\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1211.5580800310709)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1211.5580800310709, end: 2093.8978568242164)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 2093.8978568242164)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "/home/halechr/repos/NeuroPy/neuropy/core/laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (27562,) should be less than time_window_edges: (35889,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (27562,) should be less than time_window_edges: (35889,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (36246,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19981,) should be less than time_window_edges: (24848,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19981,) should be less than time_window_edges: (24848,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (25095,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (47543,) should be less than time_window_edges: (61862,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (47543,) should be less than time_window_edges: (61862,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (62479,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-08_14-26-15, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (29.16, 261.7)\n",
      "using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (27562,) should be less than time_window_edges: (35889,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (27562,) should be less than time_window_edges: (35889,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 22, 23, 36, 47, 424492)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19981,) should be less than time_window_edges: (24848,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19981,) should be less than time_window_edges: (24848,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 22, 23, 37, 49, 91993)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19981,) should be less than time_window_edges: (24848,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19981,) should be less than time_window_edges: (24848,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (27562,) should be less than time_window_edges: (35889,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (27562,) should be less than time_window_edges: (35889,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 22, 23, 39, 24, 472517)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19981,) should be less than time_window_edges: (24848,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19981,) should be less than time_window_edges: (24848,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 22, 23, 40, 26, 268505)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19981,) should be less than time_window_edges: (24848,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19981,) should be less than time_window_edges: (24848,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 67, n_all_epoch_timebins = 921)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 67, n_all_epoch_timebins = 921)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:04:54.001792\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-08_14-26-15...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-08_14-26-15...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-08_14-26-15...\n",
      "\t\t Now have 1 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_gor01_one_2006-6-09_1-22-43\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position.npy... 2006-6-09_1-22-43.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.interpolated_spike_positions.npy... 2006-6-09_1-22-43.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.mua.npy... 2006-6-09_1-22-43.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.pbe.npy... 2006-6-09_1-22-43.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 321\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1029.316608761903)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1029.316608761903, end: 1737.1968310000375)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1737.1968310000375)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (28101,) should be less than time_window_edges: (30442,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (28101,) should be less than time_window_edges: (30442,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (30745,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (18711,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (49509,) should be less than time_window_edges: (49637,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (49509,) should be less than time_window_edges: (49637,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (50132,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\n",
      "using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (28101,) should be less than time_window_edges: (30442,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (28101,) should be less than time_window_edges: (30442,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 22, 23, 53, 36, 370273)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 22, 23, 54, 0, 130679)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (28101,) should be less than time_window_edges: (30442,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (28101,) should be less than time_window_edges: (30442,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 22, 23, 54, 43, 285356)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 22, 23, 55, 6, 972238)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 71, n_all_epoch_timebins = 623)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 71, n_all_epoch_timebins = 623)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:03:19.553004\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-09_1-22-43...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-09_1-22-43...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-09_1-22-43...\n",
      "\t\t Now have 2 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_gor01_one_2006-6-12_15-55-31\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position.npy... 2006-6-12_15-55-31.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.interpolated_spike_positions.npy... 2006-6-12_15-55-31.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.mua.npy... 2006-6-12_15-55-31.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.pbe.npy... 2006-6-12_15-55-31.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 92\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 656.0648088779999)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 656.0648088779999, end: 1122.1864874939201)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1122.1864874939201)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11696,) should be less than time_window_edges: (18286,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11696,) should be less than time_window_edges: (18286,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (18467,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8515,) should be less than time_window_edges: (12817,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8515,) should be less than time_window_edges: (12817,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (12943,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20211,) should be less than time_window_edges: (31969,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20211,) should be less than time_window_edges: (31969,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (32287,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-12_15-55-31, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\n",
      "using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11696,) should be less than time_window_edges: (18286,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11696,) should be less than time_window_edges: (18286,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 4, 54, 845652)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8515,) should be less than time_window_edges: (12817,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8515,) should be less than time_window_edges: (12817,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 5, 7, 327188)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8515,) should be less than time_window_edges: (12817,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8515,) should be less than time_window_edges: (12817,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11696,) should be less than time_window_edges: (18286,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11696,) should be less than time_window_edges: (18286,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 5, 27, 699336)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8515,) should be less than time_window_edges: (12817,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8515,) should be less than time_window_edges: (12817,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 5, 40, 113128)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8515,) should be less than time_window_edges: (12817,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8515,) should be less than time_window_edges: (12817,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 36, n_all_epoch_timebins = 183)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 36, n_all_epoch_timebins = 183)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:43.652981\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-12_15-55-31...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-12_15-55-31...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-12_15-55-31...\n",
      "\t\t Now have 3 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_gor01_two_2006-6-07_16-40-19\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/2006-6-07_16-40-19.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/2006-6-07_16-40-19.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/2006-6-07_16-40-19.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/2006-6-07_16-40-19.position.npy... 2006-6-07_16-40-19.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/2006-6-07_16-40-19.interpolated_spike_positions.npy... 2006-6-07_16-40-19.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/2006-6-07_16-40-19.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/2006-6-07_16-40-19.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/2006-6-07_16-40-19.mua.npy... 2006-6-07_16-40-19.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/2006-6-07_16-40-19.pbe.npy... 2006-6-07_16-40-19.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 545\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1236.2662453636294)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1236.2662453636294, end: 2587.801681999932)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 2587.801681999932)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (36136,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (38641,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (34226,) should be less than time_window_edges: (76568,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (34226,) should be less than time_window_edges: (76568,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (77332,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-07_16-40-19, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\n",
      "using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 16, 1, 304513)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 16, 39, 408146)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 17, 17, 358566)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 17, 55, 359010)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 41, n_all_epoch_timebins = 1067)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 41, n_all_epoch_timebins = 1067)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:02:49.332214\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-07_16-40-19...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-07_16-40-19...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-07_16-40-19...\n",
      "\t\t Now have 4 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_gor01_two_2006-6-08_21-16-25\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/2006-6-08_21-16-25.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/2006-6-08_21-16-25.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/2006-6-08_21-16-25.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/2006-6-08_21-16-25.position.npy... 2006-6-08_21-16-25.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/2006-6-08_21-16-25.interpolated_spike_positions.npy... 2006-6-08_21-16-25.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/2006-6-08_21-16-25.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/2006-6-08_21-16-25.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/2006-6-08_21-16-25.mua.npy... 2006-6-08_21-16-25.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/2006-6-08_21-16-25.pbe.npy... 2006-6-08_21-16-25.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 108\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 722.653951405664)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 722.653951405664, end: 1201.0839364149142)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1201.0839364149142)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (20270,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (12894,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (34680,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-08_21-16-25, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\n",
      "using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 26, 24, 882610)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 26, 40, 665707)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 27, 9, 251058)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 27, 24, 948596)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 64, n_all_epoch_timebins = 286)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 64, n_all_epoch_timebins = 286)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:01:43.256632\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-08_21-16-25...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-08_21-16-25...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-08_21-16-25...\n",
      "\t\t Now have 5 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_gor01_two_2006-6-09_22-24-40\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/2006-6-09_22-24-40.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/2006-6-09_22-24-40.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/2006-6-09_22-24-40.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/2006-6-09_22-24-40.position.npy... 2006-6-09_22-24-40.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/2006-6-09_22-24-40.interpolated_spike_positions.npy... 2006-6-09_22-24-40.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/2006-6-09_22-24-40.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/2006-6-09_22-24-40.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/2006-6-09_22-24-40.mua.npy... 2006-6-09_22-24-40.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/2006-6-09_22-24-40.pbe.npy... 2006-6-09_22-24-40.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 512\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 911.6011600069469)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 911.6011600069469, end: 2573.457162000006)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 2573.457162000006)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (27155,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (49904,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (47040,) should be less than time_window_edges: (76857,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (47040,) should be less than time_window_edges: (76857,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (77624,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-09_22-24-40, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\n",
      "using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 38, 41, 299031)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 39, 30, 341818)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 40, 6, 386076)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 40, 55, 258464)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 58, n_all_epoch_timebins = 1410)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 58, n_all_epoch_timebins = 1410)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:05:10.022094\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-09_22-24-40...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-09_22-24-40...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-09_22-24-40...\n",
      "\t\t Now have 6 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_gor01_two_2006-6-12_16-53-46\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/2006-6-12_16-53-46.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/2006-6-12_16-53-46.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/2006-6-12_16-53-46.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/2006-6-12_16-53-46.position.npy... 2006-6-12_16-53-46.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/2006-6-12_16-53-46.interpolated_spike_positions.npy... 2006-6-12_16-53-46.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/2006-6-12_16-53-46.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/2006-6-12_16-53-46.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/2006-6-12_16-53-46.mua.npy... 2006-6-12_16-53-46.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/2006-6-12_16-53-46.pbe.npy... 2006-6-12_16-53-46.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 109\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 471.0674003356835)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 471.0674003356835, end: 785.4513262689579)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 785.4513262689579)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (13127,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (9198,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (22940,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-12_16-53-46, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\n",
      "using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 50, 48, 28281)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 50, 56, 418531)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 51, 9, 510428)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 51, 17, 873005)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 38, n_all_epoch_timebins = 187)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 38, n_all_epoch_timebins = 187)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:42.135018\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-12_16-53-46...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-12_16-53-46...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-12_16-53-46...\n",
      "\t\t Now have 7 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_vvp01_one_2006-4-09_17-29-30\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/2006-4-09_17-29-30.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/2006-4-09_17-29-30.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/2006-4-09_17-29-30.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/2006-4-09_17-29-30.position.npy... 2006-4-09_17-29-30.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/2006-4-09_17-29-30.interpolated_spike_positions.npy... 2006-4-09_17-29-30.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/2006-4-09_17-29-30.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/2006-4-09_17-29-30.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "Loading success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/2006-4-09_17-29-30.mua.npy... 2006-4-09_17-29-30.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/2006-4-09_17-29-30.pbe.npy... 2006-4-09_17-29-30.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 137\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 873.6244981772179)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 873.6244981772179, end: 1391.655627853339)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1391.655627853339)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11886,) should be less than time_window_edges: (24782,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11886,) should be less than time_window_edges: (24782,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (25027,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (14069,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20635,) should be less than time_window_edges: (40477,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20635,) should be less than time_window_edges: (40477,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (40880,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_one_2006-4-09_17-29-30, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\n",
      "using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11712,) should be less than time_window_edges: (23152,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11712,) should be less than time_window_edges: (23152,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 58, 27, 675005)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 58, 45, 63468)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11712,) should be less than time_window_edges: (23152,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11712,) should be less than time_window_edges: (23152,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 59, 20, 73902)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 0, 59, 37, 496502)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 27, n_all_epoch_timebins = 233)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 27, n_all_epoch_timebins = 233)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:42.391588\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-09_17-29-30...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-09_17-29-30...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-09_17-29-30...\n",
      "\t\t Now have 8 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_vvp01_one_2006-4-10_12-25-50\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/2006-4-10_12-25-50.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/2006-4-10_12-25-50.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/2006-4-10_12-25-50.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/2006-4-10_12-25-50.position.npy... 2006-4-10_12-25-50.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/2006-4-10_12-25-50.interpolated_spike_positions.npy... 2006-4-10_12-25-50.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/2006-4-10_12-25-50.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/2006-4-10_12-25-50.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "Loading success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/2006-4-10_12-25-50.mua.npy... 2006-4-10_12-25-50.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/2006-4-10_12-25-50.pbe.npy... 2006-4-10_12-25-50.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 39\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 883.897131568141)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 883.897131568141, end: 1413.3991723447689)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1413.3991723447689)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (26312,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (13343,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20264,) should be less than time_window_edges: (41902,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20264,) should be less than time_window_edges: (41902,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (42319,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_one_2006-4-10_12-25-50, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\n",
      "using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 6, 39, 700411)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 6, 52, 359208)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 7, 22, 974559)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 7, 35, 632458)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 107)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 107)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:29.421598\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-10_12-25-50...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-10_12-25-50...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-10_12-25-50...\n",
      "\t\t Now have 9 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_vvp01_two_2006-4-09_16-40-54\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/2006-4-09_16-40-54.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/2006-4-09_16-40-54.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/2006-4-09_16-40-54.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/2006-4-09_16-40-54.position.npy... 2006-4-09_16-40-54.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/2006-4-09_16-40-54.interpolated_spike_positions.npy... 2006-4-09_16-40-54.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/2006-4-09_16-40-54.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/2006-4-09_16-40-54.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "Loading success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/2006-4-09_16-40-54.mua.npy... 2006-4-09_16-40-54.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/2006-4-09_16-40-54.pbe.npy... 2006-4-09_16-40-54.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 47\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1155.7064689620165)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1155.7064689620165, end: 1724.0331400701689)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1724.0331400701689)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (26171,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (14863,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (16479,) should be less than time_window_edges: (42586,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (16479,) should be less than time_window_edges: (42586,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (43010,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_two_2006-4-09_16-40-54, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\n",
      "using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 13, 26, 195691)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 13, 38, 334675)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 14, 10, 48612)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 14, 22, 172057)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 23, n_all_epoch_timebins = 86)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 23, n_all_epoch_timebins = 86)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:26.643271\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-09_16-40-54...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-09_16-40-54...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-09_16-40-54...\n",
      "\t\t Now have 10 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_vvp01_two_2006-4-10_12-58-3\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/2006-4-10_12-58-3.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/2006-4-10_12-58-3.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/2006-4-10_12-58-3.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/2006-4-10_12-58-3.position.npy... 2006-4-10_12-58-3.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/2006-4-10_12-58-3.interpolated_spike_positions.npy... 2006-4-10_12-58-3.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/2006-4-10_12-58-3.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/2006-4-10_12-58-3.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "Loading success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/2006-4-10_12-58-3.mua.npy... 2006-4-10_12-58-3.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/2006-4-10_12-58-3.pbe.npy... 2006-4-10_12-58-3.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 64\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 932.8262060632987)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 932.8262060632987, end: 1458.5390641578997)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1458.5390641578997)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (27018,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (14198,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (17069,) should be less than time_window_edges: (42622,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (17069,) should be less than time_window_edges: (42622,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (43046,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_two_2006-4-10_12-58-3, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\n",
      "using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 21, 26, 104426)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 21, 50, 277091)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 22, 42, 983406)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 23, 7, 285318)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 28, n_all_epoch_timebins = 148)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 28, n_all_epoch_timebins = 148)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:44.511114\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-10_12-58-3...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-10_12-58-3...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-10_12-58-3...\n",
      "\t\t Now have 11 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_pin01_one_11-02_17-46-44\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/11-02_17-46-44.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/11-02_17-46-44.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/11-02_17-46-44.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/11-02_17-46-44.position.npy... 11-02_17-46-44.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/11-02_17-46-44.interpolated_spike_positions.npy... 11-02_17-46-44.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/11-02_17-46-44.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/11-02_17-46-44.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "externally computed ripple_df.pkl not found. Falling back to .ripple.npy...\n",
      "Loading success: .ripple.npy.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/11-02_17-46-44.mua.npy... 11-02_17-46-44.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/11-02_17-46-44.pbe.npy... 11-02_17-46-44.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 126\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1144.228403621622)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1144.228403621622, end: 1941.4332220000001)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1941.4332220000001)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (29312,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (22102,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15483,) should be less than time_window_edges: (56118,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15483,) should be less than time_window_edges: (56118,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (56677,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-02_17-46-44, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\n",
      "using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 28, 40, 804122)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 28, 55, 429747)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 29, 16, 894367)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 29, 31, 373096)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 446)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 446)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:44.987173\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_17-46-44...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_17-46-44...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_17-46-44...\n",
      "\t\t Now have 12 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_pin01_one_11-02_19-28-0\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/11-02_19-28-0.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/11-02_19-28-0.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/11-02_19-28-0.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/11-02_19-28-0.position.npy... 11-02_19-28-0.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/11-02_19-28-0.interpolated_spike_positions.npy... 11-02_19-28-0.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/11-02_19-28-0.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/11-02_19-28-0.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "externally computed ripple_df.pkl not found. Falling back to .ripple.npy...\n",
      "Loading success: .ripple.npy.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/11-02_19-28-0.mua.npy... 11-02_19-28-0.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/11-02_19-28-0.pbe.npy... 11-02_19-28-0.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 67\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 787.5080421553757)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 787.5080421553757, end: 1177.7605639999983)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1177.7605639999983)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (22485,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (11282,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (22186,) should be less than time_window_edges: (33911,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (22186,) should be less than time_window_edges: (33911,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (34248,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-02_19-28-0, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\n",
      "using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 33, 11, 555335)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 33, 17, 257868)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 33, 30, 885997)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 33, 36, 559363)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 189)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 189)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "ERROR SAVING GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_pin01_one_11-02_19-28-0. error: !! The input must be a list of SpikeTrain ::::: (<class 'TypeError'>, TypeError('The input must be a list of SpikeTrain'), <traceback object at 0x148402cdf7c0>)\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:16.249089\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5\n",
      "ERROR: encountered exception !! 'long_short_inst_spike_rate_groups' ::::: (<class 'KeyError'>, KeyError('long_short_inst_spike_rate_groups'), <traceback object at 0x14841aa9a100>) while trying to build the session HDF output for kdiba_pin01_one_11-02_19-28-0\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_19-28-0...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_19-28-0...\n",
      "ERROR: encountered exception !! The input must be a list of SpikeTrain ::::: (<class 'TypeError'>, TypeError('The input must be a list of SpikeTrain'), <traceback object at 0x1483ee9e3780>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-02_19-28-0]\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_19-28-0...\n",
      "ERROR: encountered exception !! The input must be a list of SpikeTrain ::::: (<class 'TypeError'>, TypeError('The input must be a list of SpikeTrain'), <traceback object at 0x1483e054f700>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-02_19-28-0]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_pin01_one_11-03_12-3-25\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/11-03_12-3-25.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/11-03_12-3-25.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/11-03_12-3-25.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/11-03_12-3-25.position.npy... 11-03_12-3-25.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/11-03_12-3-25.interpolated_spike_positions.npy... 11-03_12-3-25.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/11-03_12-3-25.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/11-03_12-3-25.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "externally computed ripple_df.pkl not found. Falling back to .ripple.npy...\n",
      "Loading success: .ripple.npy.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/11-03_12-3-25.mua.npy... 11-03_12-3-25.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/11-03_12-3-25.pbe.npy... 11-03_12-3-25.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 16\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 669.0602578192211)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 669.0602578192211, end: 1005.4446971784892)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1005.4446971784892)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (18921,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (9200,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15445,) should be less than time_window_edges: (28139,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15445,) should be less than time_window_edges: (28139,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (28419,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-03_12-3-25, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\n",
      "using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 36, 4, 23576)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 36, 8, 299673)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 36, 17, 130721)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 36, 21, 375122)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 22, n_all_epoch_timebins = 57)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 22, n_all_epoch_timebins = 57)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "ERROR SAVING GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_pin01_one_11-03_12-3-25. error: !! The input must be a list of SpikeTrain ::::: (<class 'TypeError'>, TypeError('The input must be a list of SpikeTrain'), <traceback object at 0x1483a66aba80>)\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:08.287854\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5\n",
      "ERROR: encountered exception !! 'long_short_inst_spike_rate_groups' ::::: (<class 'KeyError'>, KeyError('long_short_inst_spike_rate_groups'), <traceback object at 0x1483f04cef00>) while trying to build the session HDF output for kdiba_pin01_one_11-03_12-3-25\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-03_12-3-25...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-03_12-3-25...\n",
      "ERROR: encountered exception !! The input must be a list of SpikeTrain ::::: (<class 'TypeError'>, TypeError('The input must be a list of SpikeTrain'), <traceback object at 0x1483eb793780>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-03_12-3-25]\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-03_12-3-25...\n",
      "ERROR: encountered exception !! The input must be a list of SpikeTrain ::::: (<class 'TypeError'>, TypeError('The input must be a list of SpikeTrain'), <traceback object at 0x1483a5fc0040>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-03_12-3-25]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3418.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3418.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /home/halechr/turbo/Data\n",
      "\tsession_context: kdiba_pin01_one_fet11-01_12-58-54\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/fet11-01_12-58-54.epochs_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/fet11-01_12-58-54.position_info.mat... done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/fet11-01_12-58-54.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/fet11-01_12-58-54.position.npy... fet11-01_12-58-54.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/fet11-01_12-58-54.interpolated_spike_positions.npy... fet11-01_12-58-54.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/fet11-01_12-58-54.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/fet11-01_12-58-54.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "externally computed ripple_df.pkl not found. Falling back to .ripple.npy...\n",
      "Loading success: .ripple.npy.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/fet11-01_12-58-54.mua.npy... fet11-01_12-58-54.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/fet11-01_12-58-54.pbe.npy... fet11-01_12-58-54.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 469\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 2057.2259484970764)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 2057.2259484970764, end: 3031.7272470000007)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 3031.7272470000007)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (53345,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (28623,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (17876,) should be less than time_window_edges: (89950,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (17876,) should be less than time_window_edges: (89950,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (90848,)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_fet11-01_12-58-54, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "Time window 233 has no spikes.\n",
      "Time window 234 has no spikes.\n",
      "Time window 257 has no spikes.\n",
      "Time window 260 has no spikes.\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\n",
      "using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 42, 19, 177149)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 42, 33, 538927)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 43, 10, 574373)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x148439554310>: datetime.datetime(2023, 8, 23, 1, 43, 24, 868271)}\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 25, n_all_epoch_timebins = 1202)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 25, n_all_epoch_timebins = 1202)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups']. Saving global results...\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:01:27.906834\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: output/test_ExpectedVsObservedResult.h5, with key: /expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_epoch_time_bins_mean! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_LONG! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_LONG! Will be replaced by new value.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_ptp_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_mean_SHORT! Will be replaced by new value.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: clobbering existing dataset in output/test_ExpectedVsObservedResult.h5 at /expected_v_observed_result/observed_from_expected_diff_std_SHORT! Will be replaced by new value.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_fet11-01_12-58-54...\n",
      "common_file_path: output/active_across_session_scatter_plot_results.h5\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_fet11-01_12-58-54...\n",
      "\t\t done (success).\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_fet11-01_12-58-54...\n",
      "\t\t Now have 13 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multiprocessing_kwargs = dict(use_multiprocessing=False, num_processes=1)\n",
    "# multiprocessing_kwargs = dict(use_multiprocessing=True, num_processes=2)\n",
    "\n",
    "enable_full_pipeline_in_ram = False\n",
    "# enable_full_pipeline_in_ram = True\n",
    "\n",
    "# Whether to output figures:\n",
    "should_perform_figure_generation_to_file=False\n",
    "# should_perform_figure_generation_to_file=True\n",
    "\n",
    "## Included Session Contexts:\n",
    "# included_session_contexts = batch_progress_df[np.logical_and(batch_progress_df['has_user_replay_annotations'], batch_progress_df['is_ready'])]['context'].to_numpy().tolist()\n",
    "\n",
    "# Only require sessions to have replay annotations:\n",
    "# included_session_contexts = batch_progress_df[batch_progress_df['has_user_replay_annotations']]['context'].to_numpy().tolist()\n",
    "\n",
    "# included_session_contexts = batch_progress_df['context'].to_numpy().tolist()[:4] # Only get the first 6\n",
    "## Limit the contexts to run to the last N:\n",
    "# included_session_contexts = included_session_contexts[3:6]\n",
    "\n",
    "# ALL\n",
    "included_session_contexts = included_session_contexts\n",
    "\n",
    "# ## No filtering the sessions:\n",
    "# included_session_contexts = None\n",
    "\n",
    "if included_session_contexts is not None:\n",
    "    print(f'len(included_session_contexts): {len(included_session_contexts)}')\n",
    "else:\n",
    "    print(f'included_session_contexts is None so all session contexts will be included.')\n",
    "\n",
    "# included_session_contexts\n",
    "\n",
    "\n",
    "# # No Reloading\n",
    "# result_handler = BatchSessionCompletionHandler(force_reload_all=False,\n",
    "#                                                 session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=False),\n",
    "#                                                 global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=False),\n",
    "#                                                 should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False,\n",
    "#                                                 enable_full_pipeline_in_ram=enable_full_pipeline_in_ram,\n",
    "#                                                 **multiprocessing_kwargs)\n",
    "\n",
    "\n",
    "# Forced Reloading:\n",
    "result_handler = BatchSessionCompletionHandler(force_reload_all=True,\n",
    "                                                session_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=True),\n",
    "                                                global_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=True),\n",
    "                                                should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE, force_global_recompute=True,\n",
    "                                                **multiprocessing_kwargs)\n",
    "\n",
    "\n",
    "active_post_run_callback_fn = result_handler.on_complete_success_execution_session\n",
    "# active_post_run_callback_fn = _temp_on_complete_success_execution_session\n",
    "\n",
    "\n",
    "## Execute with the custom arguments.\n",
    "active_computation_functions_name_includelist=['_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation',\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "global_batch_run.execute_all(force_reload=result_handler.force_reload_all, saving_mode=result_handler.saving_mode, skip_extended_batch_computations=True, post_run_callback_fn=active_post_run_callback_fn,\n",
    "                             fail_on_exception=True, included_session_contexts=included_session_contexts,\n",
    "                                                                                        **{'computation_functions_name_includelist': active_computation_functions_name_includelist,\n",
    "                                                                                            'active_session_computation_configs': None,\n",
    "                                                                                            'allow_processing_previously_completed': True}, **multiprocessing_kwargs) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 4m 39.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de182953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import LoadedObjectPersistanceState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb4c19-1006-4e32-88c7-40f3b732b8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_progress_df[np.isin(batch_progress_df['context'].values, included_session_contexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36194ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418f6ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19afdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db966387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc83c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-08-10\n",
    "# Add output modes for .pkl and .h5 files similar to figures. For GreatLakes Batch runs, allow output to the run folder.\n",
    "\n",
    "# like the figures, file naming conventions should change for the different types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb13a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphocorehelpers.indexing_helpers import partition, safe_pandas_get_group\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor, AcrossSessionsVisualizations\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import SingleBarResult\n",
    "\n",
    "common_file_path = Path('output/active_across_session_scatter_plot_results.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "\n",
    "# InstantaneousSpikeRateGroupsComputation, : pd.DataFrame\n",
    "_shell_obj, loaded_result_df = InstantaneousFiringRatesDataframeAccessor.load_and_prepare_for_plot(common_file_path)\n",
    "# Perform the actual plotting:\n",
    "AcrossSessionsVisualizations.across_sessions_bar_graphs(_shell_obj, num_sessions=13, save_figure=False, enable_tiny_point_labels=False, enable_hover_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c02c97-a566-4e24-9219-6ee09a4075b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get only the sessions with non-None results\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "sessions_with_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e19412-2b21-4841-8207-952a04e1080b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_identifiers = included_session_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e2e13-bbdf-4c82-9fd6-8d7ac702e114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to pickle:\n",
    "saveData(global_batch_result_file_path, global_batch_run) # Update the global batch run dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf9f56e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21482b-23ac-44e6-bfb2-8e3d480d74bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine across .h5 files:\n",
    "import tables as tb\n",
    "import h5py\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import H5ExternalLinkBuilder\n",
    "\n",
    "# f'/kdiba/gor01/one/2006-6-12_15-55-31/neuron_identities/table'\n",
    "\n",
    "session_identifiers, pkl_output_paths, hdf5_output_paths\n",
    "\n",
    "file_path = f'output/test_external_links.h5'\n",
    "a_global_computations_group_key: str = f\"{session_group_key}/global_computations\"\n",
    "with tb.open_file(file_path, mode='w') as f: # this mode='w' is correct because it should overwrite the previous file and not append to it.\n",
    "    a_global_computations_group = f.create_group(session_group_key, 'global_computations', title='the result of computations that operate over many or all of the filters in the session.', createparents=True)\n",
    "    an_external_link = f.create_external_link(f'', n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb43f9-214a-401b-8ae9-7dbe9af40180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from typing import List\n",
    "from attrs import define, field, Factory\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "\n",
    "    \n",
    "session_group_keys: List[str] = [(\"/\" + a_ctxt.get_description(separator=\"/\", include_property_names=False)) for a_ctxt in session_identifiers] # 'kdiba/gor01/one/2006-6-08_14-26-15'\n",
    "# session_uid: str = session_context.get_description(separator=\"|\", include_property_names=False)\n",
    "neuron_identities_table_keys = [f\"{session_group_key}/neuron_identities/table\" for session_group_key in session_group_keys]\n",
    "\n",
    "\n",
    "a_loader = H5ExternalLinkBuilder(file_list=hdf5_output_paths, table_key_list=neuron_identities_table_keys)\n",
    "a_loader\n",
    "\n",
    "_out_table = a_loader.load_and_consolidate()\n",
    "_out_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc1ac7-5771-4cd5-94c6-7a6244eb8217",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract output files from all completed sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749849c-9f57-4d2c-aab8-5ee9353f6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5'\n",
    "\n",
    "# kdiba_vvp01_two_2006-4-10_12-58-3\n",
    "# \toutputs_local ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl')}\n",
    "# \toutputs_global ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl'), 'hdf5': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5')}\n",
    "\n",
    "session_identifiers, pkl_output_paths, hdf5_output_paths = global_batch_run.build_output_files_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361385b-385d-4e12-997b-e2a68404858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8288dee-a41a-4640-a139-cb0a64f01814",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cdc211-56e3-4e38-b02f-ea71451766eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb0cd9-3e60-4425-9351-dfc903f3f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output filelist:\n",
    "\n",
    "\n",
    "def save_filelist_to_text_file(hdf5_output_paths, filelist_path: Path):\n",
    "    _out_string = '\\n'.join([str(a_file) for a_file in hdf5_output_paths])\n",
    "    print(f'{_out_string}')\n",
    "    print(f'saving out to \"{filelist_path}\"...')\n",
    "    with open(filelist_path, 'w') as f:\n",
    "        f.write(_out_string)\n",
    "    return _out_string, filelist_path\n",
    "\n",
    "\n",
    "h5_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_HDF5_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_HDF5_savepath = save_filelist_to_text_file(hdf5_output_paths, h5_filelist_path)\n",
    "\n",
    "pkls_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_pkls_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_pkls_savepath = save_filelist_to_text_file(pkl_output_paths, pkls_filelist_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86afc323-364c-4716-a30f-97a5e4fb2af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.Filesystem.path_helpers import convert_filelist_to_new_parent\n",
    "# source_parent_path = Path(r'/media/MAX/cloud/turbo/Data')\n",
    "source_parent_path = Path(r'/nfs/turbo/umms-kdiba/Data')\n",
    "dest_parent_path = Path(r'/~/W/Data/')\n",
    "# # Build the destination filelist from the source_filelist and the two paths:\n",
    "filelist_source = hdf5_output_paths\n",
    "filelist_dest_paths = convert_filelist_to_new_parent(filelist_source, original_parent_path=source_parent_path, dest_parent_path=dest_parent_path)\n",
    "filelist_dest_paths\n",
    "\n",
    "dest_Apogee_h5_filelist_path = global_data_root_parent_path.joinpath(f'dest_fileList_Apogee_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, dest_filelist_savepath = save_filelist_to_text_file(filelist_dest_paths, dest_Apogee_h5_filelist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e69a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult\n",
    "from neuropy.core.epoch import Epoch\n",
    "\n",
    "# Save to HDF5\n",
    "suffix = f'{BATCH_DATE_TO_USE}'\n",
    "## Build Pickle Path:\n",
    "file_path = global_data_root_parent_path.joinpath(f'global_batch_output_{suffix}.h5').resolve()\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0d19b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_batch_run.to_hdf(file_path,'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ce774-98fb-4e69-a7e2-e94cbff1b0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get only the sessions with non-None results\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "\n",
    "# list(global_batch_run.session_batch_outputs.keys())\n",
    "\n",
    "# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\n",
    "across_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "# good_session_batch_outputs = global_batch_run.session_batch_outputs\n",
    "\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "good_session_batch_outputs = {a_ctxt:a_result for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\n",
    "\n",
    "for a_ctxt, a_result in good_session_batch_outputs.items():\n",
    "    if a_result is not None:\n",
    "        # a_good_result = a_result.__dict__.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\n",
    "        a_good_result = a_result.across_session_results.get('inst_fr_comps', None)\n",
    "        if a_good_result is not None:\n",
    "            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\n",
    "            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\n",
    "            \n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`\n",
    "\n",
    "## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\n",
    "AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\n",
    "\n",
    "# ## Save pickle:\n",
    "# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# # Save the all sessions instantaneous firing rate dict to the path:\n",
    "# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d19a7-5a89-43f1-aa33-3a7450d1f965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "across_sessions_instantaneous_fr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178426c-54df-47ac-8103-a66f114c77e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[a_ctxt.get_initialization_code_string() for a_ctxt in sessions_with_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be651cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-07-14 - Load Saved across-sessions-data and testing Batch-computed inst_firing_rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "# from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "# from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import list_of_dicts_to_dict_of_lists\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "## Load the saved across-session results:\n",
    "# inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "# inst_fr_output_filename = 'across_session_result_long_short_inst_firing_rate.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-21.pkl'\n",
    "# inst_fr_output_filename=f'across_session_result_handler_{BATCH_DATE_TO_USE}.pkl'\n",
    "inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-08-09_Test.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a11886",
   "metadata": {},
   "outputs": [],
   "source": [
    "across_sessions_instantaneous_frs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation` \n",
    "global_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381fcf5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "across_session_inst_fr_computation.LxC_scatter_props\n",
    "across_session_inst_fr_computation.SxC_scatter_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db1ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, InstantaneousFiringRatesDataframeAccessor, InstantaneousSpikeRateGroupsComputation, trackMembershipTypesEnum, trackExclusiveToMembershipTypeDict, trackExclusiveToMembershipTypeReverseDict\n",
    "\n",
    "## Specify the output file:\n",
    "common_file_path = Path('output/test_across_session_scatter_plot_new.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "InstantaneousFiringRatesDataframeAccessor.add_results_to_inst_fr_results_table(curr_active_pipeline, common_file_path, file_mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45d728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the unique scatter plot dictionaries:\n",
    "across_session_contexts = list(across_sessions_instantaneous_fr_dict.keys())\n",
    "unique_animals = IdentifyingContext.find_unique_values(across_session_contexts)['animal'] # {'gor01', 'pin01', 'vvp01'}\n",
    "# Get number of animals to plot\n",
    "marker_list = [(5, i) for i in np.arange(len(unique_animals))] # [(5, 0), (5, 1), (5, 2)]\n",
    "scatter_props = [{'marker': mkr} for mkr in marker_list]  # Example, you should provide your own scatter properties\n",
    "scatter_props_dict = dict(zip(unique_animals, scatter_props))\n",
    "# {'pin01': {'marker': (5, 0)},\n",
    "#  'gor01': {'marker': (5, 1)},\n",
    "#  'vvp01': {'marker': (5, 2)}}\n",
    "scatter_props_dict\n",
    "\n",
    "# Pass a function that will return a set of kwargs for a given context\n",
    "def _return_scatter_props_fn(ctxt: IdentifyingContext):\n",
    "\t\"\"\" captures `scatter_props_dict` \"\"\"\n",
    "\tanimal_id = str(ctxt.animal)\n",
    "\treturn scatter_props_dict[animal_id]\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63258151",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation # the result loaded from the file\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "# _out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)\n",
    "_out_fig_2.scatter_props_fn = _return_scatter_props_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LxC_aclus = _out_fig_2.computation_result.LxC_aclus\n",
    "SxC_aclus = _out_fig_2.computation_result.SxC_aclus\n",
    "\n",
    "LxC_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputManager, FigureOutputLocation, ContextToPathMode\n",
    "\n",
    "registered_output_files = {}\n",
    "\n",
    "def output_figure(final_context: IdentifyingContext, fig, write_vector_format:bool=False, write_png:bool=True, debug_print=True):\n",
    "    \"\"\" outputs the figure using the provided context. \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_and_write_to_file\n",
    "    def register_output_file(output_path, output_metadata=None):\n",
    "        \"\"\" registers a new output file for the pipeline \"\"\"\n",
    "        print(f'register_output_file(output_path: {output_path}, ...)')\n",
    "        registered_output_files[output_path] = output_metadata or {}\n",
    "\n",
    "    fig_out_man = FigureOutputManager(figure_output_location=FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER, context_to_path_mode=ContextToPathMode.HIERARCHY_UNIQUE)\n",
    "    active_out_figure_paths = build_and_write_to_file(fig, final_context, fig_out_man, write_vector_format=write_vector_format, write_png=write_png, register_output_file_fn=register_output_file)\n",
    "    return active_out_figure_paths, final_context\n",
    "\n",
    "\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = output_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17b920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32781c8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Single Session testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_out = global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, computation_functions_name_includelist =['_perform_baseline_placefield_computation'], active_session_computation_configs=None) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "_test_out\n",
    "\n",
    "# global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, **{'computation_functions_name_includelist': ['_perform_baseline_placefield_computation'], 'active_session_computation_configs': None}) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 23.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2bb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "full_good_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is None]\n",
    "bad_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is not None]\n",
    "full_good_dirs\n",
    "bad_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f73f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcad70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status\n",
    "global_batch_run.session_batch_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15faf2bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed516134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf02efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get the list of sessions that are completely ready to process:\n",
    "full_good_ready_to_process_sessions = list(good_only_batch_progress_df['context'].to_numpy())\n",
    "full_good_ready_to_process_sessions\n",
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ad809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run[\"good_sessions_list\"].extend(full_good_ready_to_process_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636e3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop()\n",
    "project.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf1322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\",\\n\".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # List definitions\n",
    "\n",
    "# [IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a4bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\ncurr_context = \".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # Line definitions\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5689d1d-6400-4f87-be0e-a184a1d5bee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82aedf-b024-4f07-b1a9-350730b4db8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "save_time = datetime.now()\n",
    " \n",
    "print(\"save_time =\", save_time)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = save_time.strftime(\"%Y-%m-%d_%I-%M%p\")\n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7bc6bd-5b34-41d0-b906-b0ad9927b08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get output file paths:\n",
    "completed_pipeline_filename = 'loadedSessPickle.pkl'\n",
    "completed_global_computations_filename = 'outputs/global_computation_results.pkl'\n",
    "\n",
    "full_good_ready_to_process_session_paths = list(good_only_batch_progress_df['basedirs'].to_numpy())\n",
    "session_paths_output_folders = [sess_path.joinpath('outputs').resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "\n",
    "completed_pipeline_file_paths = [sess_path.joinpath(completed_pipeline_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths = [sess_path.joinpath(completed_global_computations_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab75122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countable Additivity \n",
    "# Any countable collections of points is size 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af06e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
