{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            require([\"base/js/namespace\"], function(Jupyter) {\n                Jupyter.notebook.kernel.execute(\"notebook_path = '\" + \n                    Jupyter.notebook.notebook_path + \"'\");\n            });\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't find notebook path\n",
      "WARNING: no method worked!\n",
      "could not find notebook_path (error: expected str, bytes or os.PathLike object, not NoneType). Skipping.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from neuropy.utils.indexing_helpers import PandasHelpers\n",
    "from pyphocorehelpers.indexing_helpers import partition_df\n",
    "# Set the maximum number of columns to display\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import IPython\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "from pyphocorehelpers.notebook_helpers import NotebookCellExecutionLogger\n",
    "\n",
    "try:\n",
    "\t_notebook_path:Path = Path(IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())).resolve() # Finds the path of THIS notebook\n",
    "except Exception as e:\n",
    "\tprint(f'could not find notebook_path (error: {e}). Skipping.')\n",
    "\t_notebook_path = None # \n",
    "\t# raise e\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "# Switch to the desired interactivity mode\n",
    "plt.interactive(True)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n",
    "from pyphocorehelpers.plotting.media_output_helpers import fig_to_clipboard\n",
    "from pyphocorehelpers.Filesystem.path_helpers import file_uri_from_path, sanitize_filename_for_Windows\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, simple_path_display_widget\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_helper_save_figures, _helper_build_figure, plotly_pre_post_delta_scatter, plot_across_sessions_scatter_results\n",
    "\n",
    "# from ..PendingNotebookCode import plot_across_sessions_scatter_results, plot_histograms, plot_stacked_histograms\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import find_csv_files, find_HDF5_files, find_most_recent_files\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms_across_sessions, plot_histograms, plot_stacked_histograms\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import load_across_sessions_exported_files, _process_and_load_exported_file, _common_cleanup_operations, convert_to_dataframe\n",
    "\n",
    "from pyphocorehelpers.programming_helpers import metadata_attributes\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import build_session_t_delta, _new_process_csv_files, _old_process_csv_files\n",
    "\n",
    "debug_print: bool = False\n",
    "enable_neptune: bool = False\n",
    "\n",
    "# TODAY_DAY_DATE: str = f\"2024-09-03_Apogee\"\n",
    "TODAY_DAY_DATE: str = f\"2024-09-03_GL\"\n",
    "# TODAY_DAY_DATE: str = f\"2024-09-03_Lab\"\n",
    "# TODAY_DAY_DATE: str = f\"2024-09-03_rMBP\"\n",
    "\n",
    "print(f'TODAY_DAY_DATE: {TODAY_DAY_DATE}')\n",
    "\n",
    "types.session_str: TypeAlias = str # a unique session identifier\n",
    "\n",
    "if enable_neptune:\n",
    "    import neptune # for logging progress and results\n",
    "    from neptune.types import File\n",
    "    from pyphoplacecellanalysis.General.Batch.NeptuneAiHelpers import Neptuner, AutoValueConvertingNeptuneRun, set_environment_variables \n",
    "\n",
    "    ## Gets the notebook filepath for Neptune:\n",
    "    import IPython\n",
    "    from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "    notebook_filepath: str = IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())\n",
    "    assert Path(notebook_filepath).resolve().exists(), f\"found notebook filepath: '{notebook_filepath}' does not exist\"\n",
    "    # notebook_filepath\n",
    "\n",
    "    neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShortAcrossSessions\",\n",
    "    'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "            \n",
    "    neptuner = Neptuner(project_name=neptune_kwargs['project'], api_token=neptune_kwargs['api_token'])\n",
    "\n",
    "\n",
    "    if neptuner.run is None:\n",
    "        neptuner.run = AutoValueConvertingNeptuneRun(project=neptuner.project_name, api_token=neptuner.api_token, dependencies=\"infer\", source_files=[notebook_filepath])\n",
    "        params = {\"TODAY_DAY_DATE\": TODAY_DAY_DATE, \"run_workstation\": \"Apogee\"}\n",
    "        neptuner.run[\"parameters\"] = params\n",
    "        neptuner.outputs = neptuner.run['outputs']\n",
    "        neptuner.figures = neptuner.outputs['figures']\n",
    "\n",
    "    neptuner_run: AutoValueConvertingNeptuneRun = neptuner.run\n",
    "    \n",
    "    # run = neptune.init_run(source_files=[\"**/*.dvc\"])\n",
    "\n",
    "    # # Pre-execution dataframe view:\n",
    "    # run[\"dataset/global_batch_run_progress_df\"].upload(File.as_html(global_batch_run.to_dataframe(expand_context=True, good_only=False))) # \"path/to/test_preds.csv\"\n",
    "\n",
    "else:\n",
    "    # no neptune:\n",
    "    neptuner = None    \n",
    "    neptuner_run = None\n",
    "\n",
    "\n",
    "known_bad_sessions = [IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44')]\n",
    "known_bad_session_strs = [str(v.get_description()) for v in known_bad_sessions]\n",
    "known_bad_session_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## Load across session t_delta CSV, which contains the t_delta for each session:\n",
    "\n",
    "## INPUTS: known_bad_session_strs,\n",
    "\n",
    "# cuttoff_date = datetime(2024, 8, 29)\n",
    "cuttoff_date = datetime(2024, 7, 1)\n",
    "# cuttoff_date = datetime(2024, 5, 18)\n",
    "# cuttoff_date = None\n",
    "\n",
    "known_collected_outputs_paths = [Path(v).resolve() for v in ['/Users/pho/data/collected_outputs',\n",
    "                                                            '/Volumes/SwapSSD/Data/collected_outputs', r\"K:/scratch/collected_outputs\", '/Users/pho/Dropbox (University of Michigan)/MED-DibaLabDropbox/Data/Pho/Outputs/output/collected_outputs', r'C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs',\n",
    "                                                            '/home/halechr/FastData/collected_outputs/', '/home/halechr/cloud/turbo/Data/Output/collected_outputs']]\n",
    "collected_outputs_directory = find_first_extant_path(known_collected_outputs_paths)\n",
    "assert collected_outputs_directory.exists(), f\"collected_outputs_directory: {collected_outputs_directory} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_directory: {collected_outputs_directory}')\n",
    "\n",
    "# _active_folder_widget = fullwidth_path_widget(collected_outputs_directory)\n",
    "# display(_active_folder_widget)\n",
    "\n",
    "# Create a 'figures' subfolder if it doesn't exist\n",
    "figures_folder: Path = collected_outputs_directory.joinpath('figures').resolve()\n",
    "figures_folder.mkdir(parents=False, exist_ok=True)\n",
    "assert figures_folder.exists()\n",
    "print(f'\\tfigures_folder: {file_uri_from_path(figures_folder)}')\n",
    "\n",
    "# Create an output path for the across session collected results (like the aggregate CSVs built from the individual session CSVs)\n",
    "across_sessions_output_folder: Path = collected_outputs_directory.joinpath('../across_sessions').resolve()\n",
    "across_sessions_output_folder.mkdir(parents=False, exist_ok=True)\n",
    "assert across_sessions_output_folder.exists()\n",
    "print(f'\\tacross_sessions_output_folder: {file_uri_from_path(across_sessions_output_folder)}')\n",
    "\n",
    "## sessions' t_delta:\n",
    "t_delta_csv_path = collected_outputs_directory.joinpath('../2024-01-18_GL_t_split_df.csv').resolve() # GL\n",
    "# t_delta_csv_path = collected_outputs_directory.joinpath('2024-06-11_GL_t_split_df.csv').resolve()\n",
    "\n",
    "t_delta_df, t_delta_dict, (earliest_delta_aligned_t_start, latest_delta_aligned_t_end) = build_session_t_delta(t_delta_csv_path=t_delta_csv_path)\n",
    "\n",
    "if neptuner_run is not None:\n",
    "    _neptuner_run_parameters = dict(cuttoff_date=cuttoff_date, collected_outputs_directory=collected_outputs_directory.as_posix(), figures_folder=figures_folder.as_posix(),\n",
    "                           across_sessions_output_folder=across_sessions_output_folder.as_posix(), t_delta_csv_path=t_delta_csv_path.as_posix())\n",
    "    for k, v in _neptuner_run_parameters.items():\n",
    "        neptuner_run[f'parameters/{k}'] = v\n",
    "    _neptuner_run_parameters = {} # reset after writing\n",
    "\n",
    "## Find the files:\n",
    "csv_files = find_csv_files(collected_outputs_directory)\n",
    "h5_files = find_HDF5_files(collected_outputs_directory)\n",
    "\n",
    "csv_sessions, parsed_csv_files_df  = find_most_recent_files(found_session_export_paths=csv_files, cuttoff_date=cuttoff_date)\n",
    "h5_sessions, parsed_h5_files_df = find_most_recent_files(found_session_export_paths=h5_files)\n",
    "\n",
    "## OUTPUTS: csv_files, csv_sessions, parsed_csv_files_df\n",
    "## OUTPUTS: h5_files, h5_sessions, parsed_h5_files_df\n",
    "\n",
    "_neptuner_run_parameters = dict(csv_files=csv_files, h5_files=h5_files, csv_sessions=csv_sessions, h5_sessions=h5_sessions)\n",
    "\n",
    "# #TODO 2024-03-02 12:12: - [ ] Could add weighted correlation if there is a dataframe for that and it's computed:\n",
    "_df_raw_variable_names = ['simple_pf_pearson_merged_df', 'weighted_corr_merged_df']\n",
    "_df_variables_names = ['laps_weighted_corr_merged_df', 'ripple_weighted_corr_merged_df', 'laps_simple_pf_pearson_merged_df', 'ripple_simple_pf_pearson_merged_df']\n",
    "\n",
    "# # tbin_values_dict = {'laps': self.laps_decoding_time_bin_size, 'ripple': self.ripple_decoding_time_bin_size}\n",
    "time_col_name_dict = {'laps': 'lap_start_t', 'ripple': 'ripple_start_t'} ## default should be 't_bin_center'\n",
    "\n",
    "# fold older files:\n",
    "# {'laps_marginals_df': 'lap_start_t', 'ripple_marginals_df': 'ripple_start_t', 'laps_time_bin_marginals_df':'t_bin_center', 'ripple_time_bin_marginals_df':'t_bin_center'}\n",
    "\n",
    "if neptuner_run is not None:\n",
    "    _neptuner_run_parameters = _neptuner_run_parameters | dict(earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "                                     t_delta_df=t_delta_df)\n",
    "    for k, v in _neptuner_run_parameters.items():\n",
    "        neptuner_run[f'parsed/{k}'] = v\n",
    "    _neptuner_run_parameters = {} # reset after writing\n",
    "\n",
    "## NEW `parsed_csv_files_df1-based approach 2024-07-11 - \n",
    "## INPUTS: parsed_csv_files_df\n",
    "dict_results, df_results, excluded_or_outdated_files_list = _new_process_csv_files(parsed_csv_files_df=parsed_csv_files_df, t_delta_dict=t_delta_dict, cuttoff_date=cuttoff_date, known_bad_session_strs=known_bad_session_strs, debug_print=False) # , known_bad_session_strs=known_bad_session_strs\n",
    "(final_sessions_loaded_laps_dict, final_sessions_loaded_ripple_dict, final_sessions_loaded_laps_time_bin_dict, final_sessions_loaded_ripple_time_bin_dict, final_sessions_loaded_simple_pearson_laps_dict, final_sessions_loaded_simple_pearson_ripple_dict, final_sessions_loaded_laps_wcorr_dict, final_sessions_loaded_ripple_wcorr_dict, final_sessions_loaded_laps_all_scores_dict, final_sessions_loaded_ripple_all_scores_dict) = dict_results\n",
    "(all_sessions_laps_df, all_sessions_ripple_df, all_sessions_laps_time_bin_df, all_sessions_ripple_time_bin_df, all_sessions_simple_pearson_laps_df, all_sessions_simple_pearson_ripple_df, all_sessions_wcorr_laps_df, all_sessions_wcorr_ripple_df, all_sessions_all_scores_ripple_df) = df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sessions_loaded_laps_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Archive files that failed the load due to being older than the specified date and such\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import archive_old_files\n",
    "\n",
    "## INPUTS: collected_outputs_directory, excluded_or_outdated_files_list\n",
    "archive_folder = archive_old_files(collected_outputs_directory=collected_outputs_directory, excluded_or_outdated_files_list=excluded_or_outdated_files_list, is_dry_run=True)\n",
    "archive_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get filtered for a particular type of replay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## filter by specific set of replays:\n",
    "# dfs_list = (all_sessions_ripple_df, all_sessions_ripple_time_bin_df, all_sessions_simple_pearson_ripple_df, all_sessions_wcorr_ripple_df, all_sessions_all_scores_ripple_df)\n",
    "\n",
    "# replay_name: str = 'withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0' # 4307 rows\n",
    "replay_name: str = 'withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0' # 1417 rows, 1437 rows\n",
    "# replay_name: str = 'withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0' # 2802 rows, 2831 rows\n",
    "\n",
    "time_bin_size: float = 0.025\n",
    "# time_bin_size: float = 0.02\n",
    "# time_bin_size: float = 0.01\n",
    "filtered_all_sessions_ripple_df = deepcopy(all_sessions_ripple_df)[(all_sessions_ripple_df['custom_replay_name'] == replay_name) & (all_sessions_ripple_df['time_bin_size'] == time_bin_size)]\n",
    "filtered_all_sessions_ripple_time_bin_df = deepcopy(all_sessions_ripple_time_bin_df)[(all_sessions_ripple_time_bin_df['custom_replay_name'] == replay_name) & (all_sessions_ripple_time_bin_df['time_bin_size'] == time_bin_size)]\n",
    "filtered_all_sessions_simple_pearson_ripple_df = deepcopy(all_sessions_simple_pearson_ripple_df)[(all_sessions_simple_pearson_ripple_df['custom_replay_name'] == replay_name) & (all_sessions_simple_pearson_ripple_df['time_bin_size'] == time_bin_size)]\n",
    "filtered_all_sessions_wcorr_ripple_df = deepcopy(all_sessions_wcorr_ripple_df)[(all_sessions_wcorr_ripple_df['custom_replay_name'] == replay_name) & (all_sessions_wcorr_ripple_df['time_bin_size'] == time_bin_size)]\n",
    "filtered_all_sessions_all_scores_ripple_df = deepcopy(all_sessions_all_scores_ripple_df)[(all_sessions_all_scores_ripple_df['custom_replay_name'] == replay_name) & (all_sessions_all_scores_ripple_df['time_bin_size'] == time_bin_size)]\n",
    "## OUTPUTS: filtered_all_sessions_ripple_df, filtered_all_sessions_ripple_time_bin_df, filtered_all_sessions_simple_pearson_ripple_df, filtered_all_sessions_wcorr_ripple_df, filtered_all_sessions_all_scores_ripple_df\n",
    "# filtered_all_sessions_simple_pearson_ripple_df\n",
    "filtered_all_sessions_all_scores_ripple_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'all_sessions_ripple_df': all_sessions_ripple_df,\n",
    "    'all_sessions_ripple_time_bin_df': all_sessions_ripple_time_bin_df,\n",
    "    'all_sessions_simple_pearson_ripple_df': all_sessions_simple_pearson_ripple_df,\n",
    "    'all_sessions_wcorr_ripple_df': all_sessions_wcorr_ripple_df,\n",
    "    'all_sessions_all_scores_ripple_df': all_sessions_all_scores_ripple_df\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    unique_time_bin_counts = df.groupby('custom_replay_name')['time_bin_size'].nunique()\n",
    "    print(f\"== '{name}':\")\n",
    "    print(unique_time_bin_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_df['custom_replay_name'].unique()\n",
    "all_sessions_ripple_time_bin_df['custom_replay_name'].unique()\n",
    "all_sessions_simple_pearson_ripple_df['custom_replay_name'].unique()\n",
    "all_sessions_all_scores_ripple_df['custom_replay_name'].unique() \n",
    "\n",
    "# ['', 'withOldestImportedReplays-qclu_XX-frateThresh_0.1',\n",
    "# 'withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0',\n",
    "# 'withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0',\n",
    "# 'withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0']\n",
    "\n",
    "\n",
    "all_sessions_all_scores_ripple_df['custom_replay_name'].unique() ## OH no, only this one is missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess_names, replay_names = all_sessions_ripple_df['session_name'].str.split('__') # , maxsplit=1\n",
    "\n",
    "for a_split in all_sessions_ripple_df['session_name'].str.split('__'):\n",
    "\tprint(f'a_split: {a_split}')\n",
    "\n",
    "\tif len(a_split) > 1:\n",
    "\t\tprint(f'a_split: {a_split}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df['custom_replay_name'].unique()\n",
    "# all_sessions_ripple_df['custom_replay_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.min_rows', 50)\n",
    "# pd.set_option('display.max_rows', 50)\n",
    "# pd.set_option('display.show_dimensions', True)\n",
    "\n",
    "with pd.option_context('display.min_rows', 50, 'display.show_dimensions', True):\n",
    "    # max_elements\n",
    "    display(parsed_csv_files_df)\n",
    "\n",
    "# parsed_csv_files_df[parsed_csv_files_df['file_type'] == 'ripple_all_scores_merged_df']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_csv_files_df[parsed_csv_files_df['file_type'] == 'ripple_all_scores_merged_df']\n",
    "\n",
    "# all_sessions_all_scores_ripple_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(np.unique(parsed_csv_files_df.file_type))) # ['laps_marginals_df', 'laps_simple_pf_pearson_merged_df', 'laps_time_bin_marginals_df', 'laps_weighted_corr_merged_df', 'merged_complete_epoch_stats_df', 'ripple_all_scores_merged_df', 'ripple_marginals_df', 'ripple_simple_pf_pearson_merged_df', 'ripple_time_bin_marginals_df', 'ripple_weighted_corr_merged_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "display(parsed_csv_files_df)\n",
    "\n",
    "across_sessions_parsed_csv_files_path = across_sessions_output_folder.joinpath(f'{TODAY_DAY_DATE}_parsed_csv_files_df.csv').resolve()\n",
    "# parsed_csv_files_df.to_clipboard(excel=True)\n",
    "parsed_csv_files_df.to_csv(across_sessions_parsed_csv_files_path)\n",
    "display(fullwidth_path_widget(across_sessions_parsed_csv_files_path, file_name_label='across_sessions_parsed_csv_files_path:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import export_across_session_CSVs\n",
    "\n",
    "final_across_session_summary_CSVs_output_path = across_sessions_output_folder.resolve()\n",
    "display(fullwidth_path_widget(final_across_session_summary_CSVs_output_path, file_name_label='final_across_session_summary_CSVs_output_path:'))\n",
    "final_csv_export_paths = export_across_session_CSVs(final_output_path=final_across_session_summary_CSVs_output_path, TODAY_DAY_DATE=TODAY_DAY_DATE,\n",
    "                                                    all_sessions_laps_df=all_sessions_laps_df,  all_sessions_ripple_df=all_sessions_ripple_df,  all_sessions_laps_time_bin_df=all_sessions_laps_time_bin_df,  all_sessions_ripple_time_bin_df=all_sessions_ripple_time_bin_df, \n",
    "                                                    all_sessions_simple_pearson_laps_df=all_sessions_simple_pearson_laps_df,  all_sessions_simple_pearson_ripple_df=all_sessions_simple_pearson_ripple_df,\n",
    "                                                    all_sessions_all_scores_ripple_df=all_sessions_all_scores_ripple_df,  all_sessions_all_scores_laps_df=None,\n",
    "                                                )\n",
    "\n",
    "# final_csv_export_paths: {'AcrossSession_Laps_per-Epoch': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_Laps_per-Epoch.csv'),\n",
    "#  'AcrossSession_Ripple_per-Epoch': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_Ripple_per-Epoch.csv'),\n",
    "#  'AcrossSession_Laps_per-TimeBin': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_Laps_per-TimeBin.csv'),\n",
    "#  'AcrossSession_Ripple_per-TimeBin': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_Ripple_per-TimeBin.csv'),\n",
    "#  'AcrossSession_SimplePearson_Laps_per-Epoch': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_SimplePearson_Laps_per-Epoch.csv'),\n",
    "#  'AcrossSession_SimplePearson_Ripple_per-Epoch': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_SimplePearson_Ripple_per-Epoch.csv'),\n",
    "#  'AcrossSession_AllScores_Ripple_per-Epoch': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_AllScores_Ripple_per-Epoch.csv')}\n",
    "\n",
    "if neptuner_run is not None:\n",
    "    _neptuner_run_parameters = dict(across_sessions_parsed_csv_files_path=across_sessions_parsed_csv_files_path.as_posix(), final_across_session_summary_CSVs_output_path=final_across_session_summary_CSVs_output_path.as_posix(),\n",
    "                                       )\n",
    "    for k, v in _neptuner_run_parameters.items():\n",
    "        neptuner_run[f'output_files/{k}'] = v\n",
    "    _neptuner_run_parameters = {} # reset after writing\n",
    "\n",
    "    for k, v in final_csv_export_paths.items():\n",
    "        neptuner_run[f\"output_files/{k}\"].upload(v.resolve().as_posix())\n",
    "        \n",
    "\n",
    "final_csv_export_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import load_across_sessions_exported_h5_files\n",
    "\n",
    "## INPUTS: h5_sessions, session_dict, cuttoff_date, known_bad_session_strs\n",
    "parsed_h5_files_df, h5_contexts_paths_dict = load_across_sessions_exported_h5_files(collected_outputs_directory=collected_outputs_directory, cuttoff_date=cuttoff_date,\n",
    "                                                                                    known_bad_session_strs=known_bad_session_strs)\n",
    "h5_session_contexts = list(h5_contexts_paths_dict.keys())\n",
    "included_h5_paths = list(h5_contexts_paths_dict.values())\n",
    "\n",
    "if neptuner_run is not None:\n",
    "    _neptuner_run_parameters = dict(parsed_h5_files_df=parsed_h5_files_df,\n",
    "                                       )\n",
    "    for k, v in _neptuner_run_parameters.items():\n",
    "        neptuner_run[f'parsed/{k}'] = v\n",
    "    _neptuner_run_parameters = {} # reset after writing\n",
    "\n",
    "parsed_h5_files_df\n",
    "# h5_contexts_paths_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "included_session_contexts = deepcopy(h5_session_contexts)\n",
    "included_h5_paths = deepcopy(included_h5_paths)\n",
    "num_sessions = len(included_session_contexts)\n",
    "(neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table), output_path_dicts = AcrossSessionTables.build_and_save_all_combined_tables(included_session_contexts, included_h5_paths,\n",
    "                                                                                                                                                    override_output_parent_path=across_sessions_output_folder, output_path_suffix=f'{TODAY_DAY_DATE}',\n",
    "                                                                                                                                                    should_restore_native_column_types=True, include_csv=True, include_pkl=True)\n",
    "\n",
    "\n",
    "if neptuner_run is not None:\n",
    "    _neptuner_run_parameters = dict(neuron_identities_table=neuron_identities_table, long_short_fr_indicies_analysis_table=long_short_fr_indicies_analysis_table, neuron_replay_stats_table=neuron_replay_stats_table,\n",
    "                                       num_sessions=num_sessions)\n",
    "    for k, v in _neptuner_run_parameters.items():\n",
    "        neptuner_run[f'parsed/{k}'] = v\n",
    "    _neptuner_run_parameters = {} # reset after writing\n",
    "\n",
    "    for output_name, a_paths_dict in output_path_dicts.items():\n",
    "        for format_extension, an_output_path in a_paths_dict.items():\n",
    "            neptuner_run[f\"output_files/{format_extension}/{output_name}\"].upload(an_output_path.resolve().as_posix())\n",
    "\n",
    "\n",
    "# {'neuron_identities_table': {'.csv': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/neuron_identities_table.csv'),\n",
    "#   '.pkl': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/neuron_identities_table.pkl')},\n",
    "#  'long_short_fr_indicies_analysis_table': {'.csv': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/long_short_fr_indicies_analysis_table.csv'),\n",
    "#   '.pkl': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/long_short_fr_indicies_analysis_table.pkl')},\n",
    "#  'neuron_replay_stats_table': {'.csv': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/neuron_replay_stats_table.csv'),\n",
    "#   '.pkl': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/neuron_replay_stats_table.pkl')}}\n",
    "\n",
    "output_path_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_session_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_identities_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(neuron_replay_stats_table.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative\n",
    "\n",
    "## Move the \"height\" columns to the end\n",
    "# _neuron_columns_order_dict = dict(zip(['neuron_uid', 'format_name', 'animal', 'exper_name', 'session_name', 'neuron_type', 'aclu', 'session_uid', 'session_datetime'], np.arange(4)+4))\n",
    "\n",
    "# neuron_replay_stats_table = reorder_columns_relative(neuron_replay_stats_table, column_names=['neuron_uid', 'format_name', 'animal', 'exper_name', 'session_name', 'neuron_type', 'aclu', 'session_uid', 'session_datetime'],\n",
    "#                                                     relative_mode='end')\n",
    "neuron_replay_stats_table = reorder_columns_relative(neuron_replay_stats_table, column_names=['neuron_uid', 'format_name', 'animal', 'exper_name', 'session_name', 'neuron_type', 'aclu', 'session_uid', 'session_datetime'],\n",
    "                                                    relative_mode='start')\n",
    "\n",
    "neuron_replay_stats_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "\n",
    "# matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "AcrossSessionsResults.post_compute_all_sessions_processing(global_data_root_parent_path=collected_outputs_directory, BATCH_DATE_TO_USE=TODAY_DAY_DATE, plotting_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions) ## WORKS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(all_sessions_all_scores_ripple_df.columns)) # ['start', 'stop', 'label', 'duration', 'is_user_annotated_epoch', 'is_valid_epoch', 'P_LR', 'P_RL', 'P_Long', 'P_Short', 'P_Long_LR', 'score_long_LR', 'velocity_long_LR', 'intercept_long_LR', 'speed_long_LR', 'wcorr_long_LR', 'pearsonr_long_LR', 'travel_long_LR', 'coverage_long_LR', 'jump_long_LR', 'longest_sequence_length_ratio_long_LR', 'direction_change_bin_ratio_long_LR', 'congruent_dir_bins_ratio_long_LR', 'total_congruent_direction_change_long_LR', 'P_Long_RL', 'score_long_RL', 'velocity_long_RL', 'intercept_long_RL', 'speed_long_RL', 'wcorr_long_RL', 'pearsonr_long_RL', 'travel_long_RL', 'coverage_long_RL', 'jump_long_RL', 'longest_sequence_length_ratio_long_RL', 'direction_change_bin_ratio_long_RL', 'congruent_dir_bins_ratio_long_RL', 'total_congruent_direction_change_long_RL', 'P_Short_LR', 'score_short_LR', 'velocity_short_LR', 'intercept_short_LR', 'speed_short_LR', 'wcorr_short_LR', 'pearsonr_short_LR', 'travel_short_LR', 'coverage_short_LR', 'jump_short_LR', 'longest_sequence_length_ratio_short_LR', 'direction_change_bin_ratio_short_LR', 'congruent_dir_bins_ratio_short_LR', 'total_congruent_direction_change_short_LR', 'P_Short_RL', 'score_short_RL', 'velocity_short_RL', 'intercept_short_RL', 'speed_short_RL', 'wcorr_short_RL', 'pearsonr_short_RL', 'travel_short_RL', 'coverage_short_RL', 'jump_short_RL', 'longest_sequence_length_ratio_short_RL', 'direction_change_bin_ratio_short_RL', 'congruent_dir_bins_ratio_short_RL', 'total_congruent_direction_change_short_RL', 'ripple_start_t', 'long_best_travel', 'short_best_travel', 'travel_diff', 'long_best_coverage', 'short_best_coverage', 'coverage_diff', 'long_best_jump', 'short_best_jump', 'jump_diff', 'long_best_longest_sequence_length_ratio', 'short_best_longest_sequence_length_ratio', 'longest_sequence_length_ratio_diff', 'long_best_direction_change_bin_ratio', 'short_best_direction_change_bin_ratio', 'direction_change_bin_ratio_diff', 'long_best_congruent_dir_bins_ratio', 'short_best_congruent_dir_bins_ratio', 'congruent_dir_bins_ratio_diff', 'long_best_total_congruent_direction_change', 'short_best_total_congruent_direction_change', 'total_congruent_direction_change_diff', 'session_name', 'time_bin_size', 'delta_aligned_start_t']\n",
    "# ['long_best_total_congruent_direction_change', 'short_best_total_congruent_direction_change']\n",
    "['longest_sequence_length_ratio_diff', 'direction_change_bin_ratio_diff', 'congruent_dir_bins_ratio_diff', 'total_congruent_direction_change_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_simple_pearson_ripple_df # 3138 rows × 24 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_simple_pearson_laps_df # 931 rows × 25 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_df # 17592 rows × 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_all_scores_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_sessions_simple_pearson_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find all columns starting with 'wcorr': wcorr_long_LR\n",
    "sub_string: str = 'wcorr'\n",
    "sub_string: str = 'pearsonr'\n",
    "columns_list = list(all_sessions_simple_pearson_ripple_df.columns)\n",
    "matching_columns = [s for s in columns_list if sub_string in s]\n",
    "print(matching_columns) # ['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL', 'long_best_wcorr', 'short_best_wcorr', 'wcorr_abs_diff']\n",
    "\n",
    "['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr', 'long_best_pf_peak_x_pearsonr', 'short_best_pf_peak_x_pearsonr', 'pearsonr_abs_diff']\n",
    "['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL', 'long_best_wcorr', 'short_best_wcorr', 'wcorr_abs_diff']\n",
    "\n",
    "assert np.shape(all_sessions_simple_pearson_ripple_df)[0] == np.shape(all_sessions_all_scores_ripple_df)[0], f\"np.shape(all_sessions_all_scores_ripple_df)[0]: {np.shape(all_sessions_all_scores_ripple_df)[0]} != np.shape(all_sessions_simple_pearson_ripple_df)[0]: {np.shape(all_sessions_simple_pearson_ripple_df)[0]}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr', 'long_best_pf_peak_x_pearsonr', 'short_best_pf_peak_x_pearsonr', 'pearsonr_abs_diff']\n",
    "['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL', 'long_best_wcorr', 'short_best_wcorr', 'wcorr_abs_diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-03-02 - Get only the user-annotated ripples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import _split_user_annotated_ripple_df\n",
    "\n",
    "## Bump\n",
    "# input_df = all_sessions_simple_pearson_ripple_df\n",
    "# input_df = all_sessions_all_scores_ripple_df\n",
    "\n",
    "all_sessions_all_scores_ripple_df, (valid_ripple_df, invalid_ripple_df), (user_approved_ripple_df, user_rejected_ripple_df) = _split_user_annotated_ripple_df(all_sessions_all_scores_ripple_df)\n",
    "\n",
    "## 2024-03-14 - 'is_valid_epoch' column\n",
    "# 'is_valid_epoch'\n",
    "## OUTPUTS: valid_ripple_df, invalid_ripple_df, user_approved_ripple_df, user_rejected_ripple_df, (user_annotated_epoch_unique_session_names, unannotated_session_names)\n",
    "user_approved_ripple_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2024-02-29 - 4pm - Filter the events for those meeting wcorr criteria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df: pd.DataFrame = deepcopy(all_sessions_user_annotated_ripple_df)\n",
    "df: pd.DataFrame = deepcopy(valid_ripple_df) # valid epochs, but not just those that the user approved\n",
    "# df: pd.DataFrame = deepcopy(user_approved_ripple_df)\n",
    "\n",
    "## INPUTS: df\n",
    "\n",
    "min_wcorr_threshold: float = 0.33\n",
    "min_wcorr_diff_threshold: float = 0.2\n",
    "\n",
    "# is_included_large_wcorr_diff = np.any((df[['wcorr_abs_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "is_included_large_wcorr_diff = np.any((df[['wcorr_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "is_included_high_wcorr = np.any((df[['long_best_wcorr', 'short_best_wcorr']].abs() > min_wcorr_threshold), axis=1)\n",
    "\n",
    "df = df[is_included_high_wcorr]\n",
    "df\n",
    "\n",
    "# wcorr_long_LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_all_scores_ripple_df.time_bin_size.unique() # does not seem to return NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df.time_bin_size.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-time bin size version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import build_single_time_bin_size_dfs\n",
    "\n",
    "# Select the periods:\n",
    "# active_all_sessions_all_scores_ripple_df, (active_all_sessions_ripple_df, active_all_sessions_ripple_time_bin_df) = all_sessions_all_scores_ripple_df, (all_sessions_ripple_df, all_sessions_ripple_time_bin_df)\n",
    "active_all_sessions_all_scores_ripple_df, (active_all_sessions_ripple_df, active_all_sessions_ripple_time_bin_df) = filtered_all_sessions_all_scores_ripple_df, (filtered_all_sessions_ripple_df, filtered_all_sessions_ripple_time_bin_df)\n",
    "\n",
    "# target_time_bin_size: float = 0.005 # 0.025 # 0.08222222\n",
    "target_time_bin_size: float = 0.02\n",
    "# target_time_bin_size: float = 0.025\n",
    "\n",
    "## INPUTS: all_sessions_all_scores_ripple_df, (all_sessions_ripple_df, all_sessions_ripple_time_bin_df)\n",
    "single_time_bin_size_all_sessions_ripple_df, single_time_bin_size_all_sessions_ripple_time_bin_df = build_single_time_bin_size_dfs(all_sessions_all_scores_epochs_df=active_all_sessions_all_scores_ripple_df,\n",
    "                                                                                                            all_sessions_epochs_df=active_all_sessions_ripple_df, all_sessions_epochs_time_bin_df=active_all_sessions_ripple_time_bin_df, target_time_bin_size=target_time_bin_size,\n",
    "                                                                                                            included_columns = ['delta_aligned_start_t', 'is_user_annotated_epoch', 'is_valid_epoch'])\n",
    "\n",
    "                                                                                                            \n",
    "single_time_bin_size_all_sessions_laps_df, single_time_bin_size_all_sessions_laps_time_bin_df = build_single_time_bin_size_dfs(all_sessions_all_scores_epochs_df=all_sessions_simple_pearson_laps_df,\n",
    "                                                                                                            all_sessions_epochs_df=all_sessions_laps_df, all_sessions_epochs_time_bin_df=all_sessions_laps_time_bin_df, target_time_bin_size=target_time_bin_size,\n",
    "                                                                                                            included_columns = ['delta_aligned_start_t',])\n",
    "\n",
    "## OUTPUTS: single_time_bin_size_all_sessions_ripple_df, single_time_bin_size_all_sessions_ripple_time_bin_df\n",
    "## OUTPUTS: single_time_bin_size_all_sessions_laps_df, single_time_bin_size_all_sessions_laps_time_bin_df \n",
    "\n",
    "single_time_bin_size_all_sessions_laps_df\n",
    "\n",
    "\n",
    "# # Recover the important columns from the newer `all_sessions_all_scores_ripple_df`\n",
    "# included_columns = ['delta_aligned_start_t', 'is_user_annotated_epoch', 'is_valid_epoch']  # Added 'delta_aligned_start_t' for the merge\n",
    "# single_time_bin_size_all_sessions_ripple_df = pd.merge(single_time_bin_size_all_sessions_ripple_df, \n",
    "#                      all_sessions_all_scores_ripple_df[included_columns], \n",
    "#                      on='delta_aligned_start_t', \n",
    "#                      how='left')\n",
    "\n",
    "\n",
    "# single_time_bin_size_all_sessions_ripple_df\n",
    "## OUTPUTS: single_time_bin_size_all_sessions_ripple_df, single_time_bin_size_all_sessions_ripple_df\n",
    "# single_time_bin_size_all_sessions_ripple_time_bin_df\n",
    "all_sessions_simple_pearson_laps_df\n",
    "single_time_bin_size_all_sessions_laps_time_bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS: all_sessions_all_scores_ripple_df, (all_sessions_ripple_df, all_sessions_ripple_time_bin_df)\n",
    "all_sessions_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting via Plotly\n",
    "`!pip install kaleido==\"v0.1.0.post1\" `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.plotly_templates import PlotlyHelpers\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms_across_sessions, plot_stacked_histograms\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_helper_save_figures, _helper_build_figure, plotly_pre_post_delta_scatter, plot_across_sessions_scatter_results\n",
    "\n",
    "# fig_size_kwargs = {'width': 1650, 'height': 480}\n",
    "resolution_multiplier = 1\n",
    "# fig_size_kwargs = {'width': resolution_multiplier*1650, 'height': resolution_multiplier*480}\n",
    "fig_size_kwargs = {'width': resolution_multiplier*1920, 'height': resolution_multiplier*480}\n",
    "is_dark_mode, template = PlotlyHelpers.get_plotly_template(is_dark_mode=False)\n",
    "pio.templates.default = template\n",
    "\n",
    "# figure_export_path = Path(r'E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Presentations\\2024-05-30 - Pho iNAV Poster\\Figures').resolve()\n",
    "# figure_export_path = Path('/Users/pho/Dropbox (Personal)/Active/Kamran Diba Lab/Presentations/2024-05-30 - Pho iNAV Poster/Figures').resolve()\n",
    "\n",
    "# assert figure_export_path.exists()\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from pyphocorehelpers.programming_helpers import copy_image_to_clipboard\n",
    "\n",
    "def save_plotly(a_fig, a_fig_context):\n",
    "    \"\"\" \n",
    "    captures: TODAY_DAY_DATE, figures_folder, neptuner_run\n",
    "    \"\"\"\n",
    "    fig_save_path: Path = figures_folder.joinpath('_'.join([TODAY_DAY_DATE, sanitize_filename_for_Windows(a_fig_context.get_description())])).resolve()\n",
    "    figure_out_paths = {'.html': fig_save_path.with_suffix('.html'), '.png': fig_save_path.with_suffix('.png')}\n",
    "    a_fig.write_html(figure_out_paths['.html'])\n",
    "    display(fullwidth_path_widget(figure_out_paths['.html'], file_name_label='.html'))\n",
    "    # print(file_uri_from_path(figure_out_paths['.html']))\n",
    "    a_fig.write_image(figure_out_paths['.png'])\n",
    "    # print(file_uri_from_path(figure_out_paths['.png']))\n",
    "    display(fullwidth_path_widget(figure_out_paths['.png'], file_name_label='.png'))\n",
    "\n",
    "    if neptuner_run is not None:\n",
    "        a_full_figure_path_key: str = a_fig_context.get_description(separator='/', include_property_names=True, key_value_separator=':') # .replace(' ', '_')\n",
    "        # a_full_figure_path_key: str = a_fig_context.get_description(separator=':', include_property_names=True, key_value_separator='|')\n",
    "        print(f'a_full_figure_path_key: \"{a_full_figure_path_key}\"')\n",
    "        # neptuner_run['outputs']['figures'][f\"{a_full_figure_path_key}\"].upload(a_fig)\n",
    "        neptuner_run['outputs']['figures'][f\"{a_full_figure_path_key}\"].upload(figure_out_paths['.html'].as_posix())\n",
    "        # neptuner.figures[f\"{a_full_figure_path_key}\"].upload(a_fig)\n",
    "        \n",
    "    return figure_out_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'short_best_wcorr', 'long_best_wcorr', 'wcorr_diff'\n",
    "# 'pearsonr_long_LR', 'long_best_wcorr', 'wcorr_diff'\n",
    "all_sessions_all_scores_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "histogram_bins = 25\n",
    "num_sessions = 1\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(df)\n",
    "## INPUTS: all_sessions_all_scores_ripple_df\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(concatenated_ripple_df)\n",
    "# concatenated_ripple_df = deepcopy(all_sessions_ripple_df)\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(filtered_all_sessions_wcorr_ripple_df)\n",
    "\n",
    "concatenated_ripple_df = deepcopy(filtered_all_sessions_all_scores_ripple_df)\n",
    "\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(all_sessions_all_scores_ripple_df)\n",
    "# concatenated_ripple_df = concatenated_ripple_df[concatenated_ripple_df['custom_replay_name'] != ''] # non-custom\n",
    "# concatenated_ripple_df = deepcopy(filtered_all_sessions_all_scores_ripple_df)\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(all_sessions_ripple_time_bin_df)\n",
    "# concatenated_ripple_df = deepcopy(all_sessions_all_scores_ripple_df)\n",
    "# concatenated_ripple_df = deepcopy(single_time_bin_size_all_sessions_ripple_df)\n",
    "display(concatenated_ripple_df)\n",
    "# ['longest_sequence_length_ratio_diff', 'direction_change_bin_ratio_diff', 'congruent_dir_bins_ratio_diff', 'total_congruent_direction_change_diff']\n",
    "\n",
    "\n",
    "# variable_name = 'P_Long'\n",
    "# variable_name = 'P_Short' # Shows expected effect - short-only replay prior to delta and then split replays post-delta\n",
    "variable_name = 'short_best_wcorr'\n",
    "# variable_name = 'long_best_pf_peak_x_pearsonr'\n",
    "# variable_name = 'long_best_jump'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "# variable_name = 'pearsonr_abs_diff'\n",
    "# variable_name = 'direction_change_bin_ratio_diff'\n",
    "# variable_name = 'longest_sequence_length_ratio_diff'\n",
    "# variable_name = 'long_best_longest_sequence_length_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'congruent_dir_bins_ratio_diff'\n",
    "# variable_name = 'total_congruent_direction_change_diff'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'long_best_direction_change_bin_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "\n",
    "\n",
    "concatenated_ripple_df = concatenated_ripple_df[concatenated_ripple_df[variable_name].abs() > 0.25]\n",
    "\n",
    "# y_baseline_level: float = 0.5 # for P(short), etc\n",
    "y_baseline_level: float = 0.0 # for wcorr, etc\n",
    "\n",
    "# px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# px_scatter_kwargs.pop('color')\n",
    "\n",
    "\n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "hist_kwargs.pop('color')\n",
    "\n",
    "px_scatter_kwargs['color'] = 'custom_replay_name'\n",
    "hist_kwargs['color'] = 'custom_replay_name'\n",
    "\n",
    "\n",
    "new_fig_ripples, new_fig_ripples_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), legend_title_text=None, is_dark_mode=is_dark_mode)\n",
    "\n",
    "new_fig_ripples = new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "_extras_output_dict = {}\n",
    "if is_dark_mode:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=y_baseline_level, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "else:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=y_baseline_level, line=dict(color=\"rgba(0.2,0.2,0.2,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "new_fig_ripples_context = new_fig_ripples_context.adding_context_if_missing(num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=new_fig_ripples_context)\n",
    "new_fig_ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_bins = 25\n",
    "num_sessions = 1\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(filtered_all_sessions_wcorr_ripple_df)\n",
    "concatenated_ripple_df = deepcopy(filtered_all_sessions_simple_pearson_ripple_df) # ['P_LR', 'P_RL', 'P_Long', 'P_Short', 'ripple_idx', 'ripple_start_t', 'P_Long_LR', 'P_Long_RL', 'P_Short_LR', 'P_Short_RL', 'most_likely_decoder_index', 'start', 'stop', 'label', 'duration', 'long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr', 'best_decoder_index', 'session_name', 'time_bin_size', 'delta_aligned_start_t', 'is_user_annotated_epoch', 'is_valid_epoch', 'custom_replay_name', 'epoch_idx', 'long_best_pf_peak_x_pearsonr', 'short_best_pf_peak_x_pearsonr', 'wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL', 'long_best_wcorr', 'short_best_wcorr', 'wcorr_abs_diff', 'pearsonr_abs_diff']\n",
    "\n",
    "print(f'concatenated_ripple_df.columns: {list(concatenated_ripple_df.columns)}')\n",
    "# variable_name = 'P_Long'\n",
    "variable_name = 'P_Short' # Shows expected effect - short-only replay prior to delta and then split replays post-delta\n",
    "# variable_name = 'short_best_wcorr'\n",
    "# variable_name = 'long_best_pf_peak_x_pearsonr'\n",
    "# variable_name = 'long_best_jump'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "# variable_name = 'short_best_wcorr'\n",
    "# variable_name = 'wcorr_long_LR'\n",
    "# variable_name = 'pearsonr_abs_diff'\n",
    "# variable_name = 'direction_change_bin_ratio_diff'\n",
    "# variable_name = 'longest_sequence_length_ratio_diff'\n",
    "# variable_name = 'long_best_longest_sequence_length_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'congruent_dir_bins_ratio_diff'\n",
    "# variable_name = 'total_congruent_direction_change_diff'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'long_best_direction_change_bin_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "\n",
    "y_baseline_level: float = 0.5 # for P(short), etc\n",
    "# y_baseline_level: float = 0.0 # for wcorr, etc\n",
    "\n",
    "# px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# px_scatter_kwargs.pop('color')\n",
    "\n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "hist_kwargs.pop('color')\n",
    "new_fig_ripples, new_fig_ripples_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), legend_title_text=None, is_dark_mode=is_dark_mode)\n",
    "\n",
    "new_fig_ripples = new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "\n",
    "_extras_output_dict = {}\n",
    "if is_dark_mode:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=y_baseline_level, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "else:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=y_baseline_level, line=dict(color=\"rgba(0.2,0.2,0.2,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "new_fig_ripples_context = new_fig_ripples_context.adding_context_if_missing(num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "# figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=new_fig_ripples_context)\n",
    "new_fig_ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_name = 'short_best_direction_change_bin_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "variable_name = 'short_best_wcorr'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], , 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"pre_post_delta_category\") # , histnorm='probability density'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), is_dark_mode=is_dark_mode)\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.0, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples.show()\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=figure_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_name = 'total_congruent_direction_change_diff'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'long_best_total_congruent_direction_change'\n",
    "variable_name = 'wcorr_diff'\n",
    "# variable_name = 'long_best_wcorr'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\", 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], \n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), is_dark_mode=is_dark_mode)\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.0, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples.show()\n",
    "\n",
    "figure_context = figure_context.adding_context_if_missing(num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=figure_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import _perform_stats_tests\n",
    "\n",
    "# stats_variable_name: str = 'P_Short'\n",
    "# stats_variable_name: str = 'short_best_direction_change_bin_ratio'\n",
    "# stats_variable_name: str = 'short_best_wcorr'\n",
    "\n",
    "\n",
    "shuffle_results, p_value, f_value, (dof1, dof2), (variance1, variance2) = _perform_stats_tests(valid_ripple_df, stats_variable_name='short_best_wcorr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that wcorr in both periods is higher than shuffles\n",
    "\n",
    "\n",
    "stats_variable_name = 'short_best_wcorr'\n",
    "# stats_variable_name = 'long_best_wcorr'\n",
    "# stats_variable_name = 'long_best_wcorr'\n",
    "\n",
    "\n",
    "\n",
    "shuffle_results, p_value, f_value, (dof1, dof2), (variance1, variance2) = _perform_stats_tests(deepcopy(concatenated_ripple_df), stats_variable_name=stats_variable_name)\n",
    "\n",
    "\n",
    "# stats_variable_name: \"short_best_wcorr\" -- actual_diff_means: -0.00983910691641765\n",
    "# stats_variable_name: short_best_wcorr\n",
    "# Statistics=72308.00, p=0.73\n",
    "# Do not Reject Null Hypothesis (No significant difference between two samples)\n",
    "# Variance 1: 0.1395112660465373\n",
    "# Variance 2: 0.18436187114204847\n",
    "# Degree of freedom 1: 395\n",
    "# Degree of freedom 2: 359\n",
    "# F-statistic: 0.756725157877388\n",
    "# p-value: 0.003419223265796241\n",
    "\n",
    "# stats_variable_name: \"long_best_wcorr\" -- actual_diff_means: -0.0028337579937901397\n",
    "# stats_variable_name: long_best_wcorr\n",
    "# Statistics=71529.00, p=0.93\n",
    "# Do not Reject Null Hypothesis (No significant difference between two samples)\n",
    "# Variance 1: 0.1659575407149896\n",
    "# Variance 2: 0.20687539745971859\n",
    "# Degree of freedom 1: 395\n",
    "# Degree of freedom 2: 359\n",
    "# F-statistic: 0.8022101359215698\n",
    "# p-value: 0.016221081810852238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User non-selected:\n",
    "scatter_title = f'user_approved_ripple_df Several Sessions {variable_name}'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': scatter_title, 'range_y': [0.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size'}} # , 'color': 'time_bin_size'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(user_approved_ripple_df), out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), is_dark_mode=is_dark_mode)\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEA: The ones with clear replays (diagonal sequences in the decoded posteriors) are by definiition ambiguous, because there's not much difference between the long/short decoders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User non-selected:\n",
    "scatter_title = f'Non-selected Several Sessions {variable_name}'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': scatter_title, 'range_y': [0.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size'}} # , 'color': 'time_bin_size'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(user_rejected_ripple_df), out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end))\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laps test\n",
    "concatenated_ripple_df = deepcopy(all_sessions_simple_pearson_laps_df)\n",
    "\n",
    "scatter_title = 'Several Sessions'\n",
    "variable_name = 'wcorr_abs_diff'\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': scatter_title, 'range_y': [0.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size'}} \n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(concatenated_ripple_df), out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end))\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\n",
    "# from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import plot_across_sessions_scatter_results\n",
    "\n",
    "# Example usage:\n",
    "all_session_figures = plot_across_sessions_scatter_results(collected_outputs_directory, concatenated_laps_df=all_sessions_laps_df, concatenated_ripple_df=all_sessions_ripple_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t#    enabled_time_bin_sizes=[0.03, 0.10],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   laps_title_prefix=f\"Laps\", ripple_title_prefix=f\"Ripples\", save_figures=True, figure_save_extension=['.html','.png'], is_dark_mode=is_dark_mode)\n",
    "fig_laps, fig_ripples = all_session_figures[0]\n",
    "# fig_laps.update_layout(fig_size_kwargs)\n",
    "# fig_ripples.update_layout(fig_size_kwargs)\n",
    "\n",
    "# fig_laps.show()\n",
    "fig_ripples.show()\n",
    "# fig_laps.write_html(f\"../output/{TODAY_DAY_DATE}_AcrossSession_fig_laps.html\")\n",
    "# fig_ripples.write_html(f\"../output/{TODAY_DAY_DATE}_AcrossSession_fig_ripples.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_context = figure_context.adding_context_if_missing(num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_to_clipboard(fig_ripples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "## time_bin version:\n",
    "all_time_bin_session_figures = plot_across_sessions_scatter_results(collected_outputs_directory, concatenated_laps_df=all_sessions_laps_time_bin_df, concatenated_ripple_df=all_sessions_ripple_time_bin_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t#    enabled_time_bin_sizes=[0.03, 0.10],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   main_plot_mode='separate_row_per_session',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   laps_title_prefix=f\"Laps_per_time_bin\", ripple_title_prefix=f\"Ripples_per_time_bin\", save_figures=True, figure_save_extension=['.html','.png'], is_dark_mode=is_dark_mode)\n",
    "fig_time_bin_laps, fig_time_bin_ripples = all_time_bin_session_figures[0]\n",
    "# fig_time_bin_laps.show()\n",
    "fig_time_bin_ripples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test collapsed histograms-only results:\n",
    "histograms_only_all_time_bin_session_figures = plot_across_sessions_scatter_results(collected_outputs_directory, concatenated_laps_df=all_sessions_laps_time_bin_df, concatenated_ripple_df=all_sessions_ripple_time_bin_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t#    enabled_time_bin_sizes=[0.03, 0.10],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# enabled_time_bin_sizes=[0.03, 0.058, 0.10], # [0.03 , 0.044, 0.058, 0.072, 0.086, 0.1]\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   main_plot_mode='default',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   laps_title_prefix=f\"Laps_per_time_bin\", ripple_title_prefix=f\"Ripples_per_time_bin\", save_figures=False, figure_save_extension=['.html','.png'])\n",
    "histograms_only_fig_time_bin_laps, histograms_only_fig_time_bin_ripples = histograms_only_all_time_bin_session_figures[0]\n",
    "# histograms_only_fig_time_bin_laps.show()\n",
    "histograms_only_fig_time_bin_ripples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.subplots as sp\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "all_session_figures = plot_across_sessions_scatter_results(collected_outputs_directory, concatenated_laps_df=single_time_bin_size_all_sessions_laps_df, concatenated_ripple_df=single_time_bin_size_all_sessions_ripple_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t#    enabled_time_bin_sizes=[0.03, 0.10],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   laps_title_prefix=f\"Laps\", ripple_title_prefix=f\"Ripples\", save_figures=True, figure_save_extension=['.html','.png'], is_dark_mode=is_dark_mode, main_plot_mode='default')\n",
    "fig_laps, fig_ripples = all_session_figures[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "\n",
    "# data_results_df: pd.DataFrame = deepcopy(all_sessions_laps_df) # all_sessions_laps_time_bin_df\n",
    "data_results_df: pd.DataFrame = deepcopy(single_time_bin_size_all_sessions_laps_time_bin_df).infer_objects()\n",
    "\n",
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "new_laps_fig, new_laps_fig_context = plotly_pre_post_delta_scatter(data_results_df=data_results_df, out_scatter_fig=fig_laps, histogram_bins=histogram_bins, px_scatter_kwargs=dict(title='Laps'))\n",
    "\n",
    "\n",
    "# new_laps_fig = new_laps_fig.update_layout(fig_size_kwargs, \n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     ),\n",
    "# )\n",
    "# Update x-axis labels\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=1)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Delta-aligned Event Time (seconds)\", row=1, col=2)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=3)\n",
    "\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_laps_fig.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "new_laps_fig\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "\n",
    "new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='laps', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "figure_out_paths = save_plotly(a_fig=new_laps_fig, a_fig_context=new_laps_fig_context)\n",
    "new_laps_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data_results_df['time_bin_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_results_df[data_results_df['time_bin_size'] == 0.005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib-based versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms_across_sessions, plot_stacked_histograms\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #TODO 2024-06-05 09:15: - [ ] Define save_matplotlib function\n",
    "new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='laps', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Spike3D.PendingNotebookCode import plot_stacked_histograms\n",
    "\n",
    "# You can use it like this:'long_best_dir_simple_pearsonr'\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms_across_sessions(data_type='Laps', session_spec='All Sessions', data_results_df=all_sessions_laps_time_bin_df, time_bin_duration_str=\"75 ms\")\n",
    "_out1: \"MatplotlibRenderPlots\" = plot_histograms_across_sessions(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig_to_clipboard(_out0.figures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all_sessions_new_laps_df, all_sessions_new_ripple_df\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms_across_sessions(data_type='New Laps', session_spec='All Sessions', data_results_df=all_sessions_new_laps_df, time_bin_duration_str=\"25 ms\")\n",
    "_out1: \"MatplotlibRenderPlots\" = plot_histograms_across_sessions(data_type='New Ripples', session_spec='All Sessions', data_results_df=all_sessions_new_ripple_df, time_bin_duration_str=\"25 ms\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_new_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_sessions_new_laps_df['session_name'].unique()) # 10 sessions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "column_name: str = 'P_Short'\n",
    "\n",
    "# You can use it like this:\n",
    "num_unique_sessions: int = all_sessions_laps_time_bin_df.session_name.nunique(dropna=True) # number of unique sessions, ignoring the NA entries\n",
    "num_unique_time_bins: int = all_sessions_laps_time_bin_df.time_bin_size.nunique(dropna=True)\n",
    "_laps_histogram_out = plot_stacked_histograms(all_sessions_laps_time_bin_df, 'Laps', f'{num_unique_sessions} Sessions', f\"{num_unique_time_bins} tbin sizes\", column_name=column_name)\n",
    "\n",
    "fig_to_clipboard(_laps_histogram_out.figures[0])\n",
    "\n",
    "num_unique_sessions: int = all_sessions_ripple_time_bin_df.session_name.nunique(dropna=True) # number of unique sessions, ignoring the NA entries\n",
    "num_unique_time_bins: int = all_sessions_ripple_time_bin_df.time_bin_size.nunique(dropna=True)\n",
    "_ripple_histogram_out = plot_stacked_histograms(all_sessions_ripple_time_bin_df, 'Ripples', f'{num_unique_sessions} Sessions', f\"{num_unique_time_bins} tbin sizes\", column_name=column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df['time_bin_size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_time_bin_size: float = 0.072 # 0.058\n",
    "# active_time_bin_size: float = 0.086\n",
    "# active_time_bin_size: float = 0.1 # looks the most bimodal with as little of an intermediate value as possible.\n",
    "active_time_bin_size: float = 0.13444444 # looks the most bimodal with as little of an intermediate value as possible.\n",
    "_single_time_bin_ripple_histogram_out = plot_stacked_histograms(all_sessions_ripple_time_bin_df[np.isclose(all_sessions_ripple_time_bin_df['time_bin_size'], active_time_bin_size)], 'Ripples', f'{num_unique_sessions} Sessions', f\"tbin: {active_time_bin_size:0.3f}s\", column_name=column_name)\n",
    "fig_to_clipboard(_single_time_bin_ripple_histogram_out.figures[0], bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_to_clipboard(_ripple_histogram_out.figures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_laps_histogram_out.figures[0]\n",
    "\n",
    "figures_folder\n",
    "\n",
    "figures_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🟢🔜 2024-03-28 - AcrossSessionTable (PhoDibaPaper2023 formats) .h5 and figure exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "\n",
    "\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True)\n",
    "num_sessions: int = len(long_short_fr_indicies_analysis_table['session_uid'].unique())\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "long_short_fr_indicies_analysis_table\n",
    "\n",
    "\n",
    "def _save_matplotlib_fig(matplotlib_output_container: MatplotlibRenderPlots):\n",
    "\n",
    "    a_fig_context = matplotlib_output_container.context\n",
    "    assert len(matplotlib_output_container.saved_figures) == 1\n",
    "    a_saved_fig_path = matplotlib_output_container.saved_figures[0][0]\n",
    "    assert a_saved_fig_path.exists()\n",
    "\n",
    "    if neptuner_run is not None:\n",
    "        a_full_figure_path_key: str = a_fig_context.get_description(separator='/', include_property_names=True, key_value_separator=':') # .replace(' ', '_')\n",
    "        # a_full_figure_path_key: str = a_fig_context.get_description(separator=':', include_property_names=True, key_value_separator='|')\n",
    "        print(f'a_full_figure_path_key: \"{a_full_figure_path_key}\"')\n",
    "        # neptuner_run['outputs']['figures'][f\"{a_full_figure_path_key}\"].upload(a_fig)\n",
    "        neptuner_run['outputs']['figures'][f\"{a_full_figure_path_key}\"].upload(a_saved_fig_path.as_posix())\n",
    "        # neptuner.figures[f\"{a_full_figure_path_key}\"].upload(a_fig)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "matplotlib_output_container: MatplotlibRenderPlots = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions)\n",
    "\n",
    "# graphics_output_dict.figures[0]\n",
    "# graphics_output_dict.context\n",
    "_save_matplotlib_fig(matplotlib_output_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphics_output_dict.saved_figures[0][0] #.plot_data['saved_figures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import fig_to_clipboard\n",
    "\n",
    "# copy_image_to_clipboard(graphics_output_dict['figures'][0])\n",
    "fig_to_clipboard(matplotlib_output_container.figures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_long_and_short_firing_rate_replays_v_laps_figure(neuron_replay_stats_table=neuron_replay_stats_table, num_sessions=num_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_matplotlib_fig(graphics_output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptuner.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2024-07-08 - Single Session Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = Path(r\"K:\\scratch\\collected_outputs\\2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_marginals_df).csv\").resolve()\n",
    "assert csv_path.exists()\n",
    "\n",
    "ripple_df = pd.read_csv(csv_path)\n",
    "ripple_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Spike3D.PendingNotebookCode import plot_stacked_histograms\n",
    "\n",
    "# You can use it like this:'long_best_dir_simple_pearsonr'\n",
    "_out1: \"MatplotlibRenderPlots\" = plot_histograms_across_sessions(data_type='Ripples', session_spec='All Sessions', data_results_df=ripple_df, time_bin_duration_str=\"20 ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "\n",
    "# data_results_df: pd.DataFrame = deepcopy(all_sessions_laps_df) # all_sessions_laps_time_bin_df\n",
    "# data_results_df: pd.DataFrame = deepcopy(ripple_df[['P_LR', 'P_RL', 'P_Long', 'P_Short', 'ripple_start_t', 'delta_aligned_start_t', 'time_bin_size']]).infer_objects()\n",
    "data_results_df: pd.DataFrame = deepcopy(ripple_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]).infer_objects()\n",
    "data_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data_results_df.columns)) # ['Unnamed: 0', 'P_LR', 'P_RL', 'P_Long', 'P_Short', 'ripple_idx', 'ripple_start_t', 'session_name', 'delta_aligned_start_t', 'time_bin_size']\n",
    "['P_LR', 'P_RL', 'P_Long', 'P_Short', 'ripple_start_t', 'delta_aligned_start_t', 'time_bin_size']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "new_ripple_fig, new_ripple_fig_context = plotly_pre_post_delta_scatter(data_results_df=data_results_df, out_scatter_fig=None, histogram_bins=histogram_bins, px_scatter_kwargs=dict(title='Ripple'), histogram_variable_name='P_Short')\n",
    "new_ripple_fig\n",
    "\n",
    "\n",
    "# new_laps_fig = new_laps_fig.update_layout(fig_size_kwargs, \n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     ),\n",
    "# )\n",
    "# Update x-axis labels\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=1)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Delta-aligned Event Time (seconds)\", row=1, col=2)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=3)\n",
    "\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_ripple_fig.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "new_ripple_fig\n",
    "\n",
    "\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "\n",
    "# new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='withNewKamranExportedReplays', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "# figure_out_paths = save_plotly(a_fig=new_laps_fig, a_fig_context=new_laps_fig_context)\n",
    "# new_laps_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
