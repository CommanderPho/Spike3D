{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"2024-01-08 - Batch Run Progress Tracker.ipynb\"\n",
    "\n",
    "Serves to keep track of the status, results, and effects of various runs of the pipeline. For example when a certain run on a certain machine throws and error and produces a stacktrace, at a minimum that stacktrace should be accessible later in a manner more or equally conveninet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Optional, Union, Callable\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "from attrs import define, field, Factory\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions import ComputationFunctionRegistryHolder # should include ComputationFunctionRegistryHolder and all specifics\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ComputationFunctionRegistryHolder import ComputationFunctionRegistryHolder\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.MultiContextComputationFunctions import _wrap_multi_context_computation_function\n",
    "\n",
    "from pyphocorehelpers.exception_helpers import CapturedException # used in _execute_computation_functions for error handling\n",
    "from pyphocorehelpers.programming_helpers import metadata_attributes\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import FunctionsSearchMode\n",
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import SpecificComputationValidator, SpecificComputationResultsSpecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@define(slots=False, repr=False)\n",
    "class ComputationFunctionManager:\n",
    "    \"\"\"Built from `ComputedPipelineStage`\n",
    "\n",
    "    global_comparison_results has keys of type IdentifyingContext\n",
    "    \"\"\"\n",
    "    registered_computation_function_dict: Dict = field(default=Factory(dict), repr=True)\n",
    "    registered_global_computation_function_dict: Dict = field(default=Factory(dict), repr=True)\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def registered_computation_functions(self):\n",
    "        return list(self.registered_computation_function_dict.values())\n",
    "    @property\n",
    "    def registered_computation_function_names(self):\n",
    "        return list(self.registered_computation_function_dict.keys()) \n",
    "\n",
    "\n",
    "    @property\n",
    "    def registered_global_computation_functions(self):\n",
    "        return list(self.registered_global_computation_function_dict.values())\n",
    "    @property\n",
    "    def registered_global_computation_function_names(self):\n",
    "        return list(self.registered_global_computation_function_dict.keys()) \n",
    "\n",
    "\n",
    "    # 'merged' refers to the fact that both global and non-global computation functions are included _____________________ #\n",
    "    @property\n",
    "    def registered_merged_computation_function_dict(self):\n",
    "        \"\"\"build a merged function dictionary containing both global and non-global functions:\"\"\"\n",
    "        return (self.registered_global_computation_function_dict | self.registered_computation_function_dict)\n",
    "    @property\n",
    "    def registered_merged_computation_functions(self):\n",
    "        return list(self.registered_merged_computation_function_dict.values())\n",
    "    @property\n",
    "    def registered_merged_computation_function_names(self):\n",
    "        return list(self.registered_merged_computation_function_dict.keys()) \n",
    "\n",
    "    def get_merged_computation_function_validators(self) -> Dict[str, SpecificComputationValidator]:\n",
    "        ## From the registered computation functions, gather any validators and build the SpecificComputationValidator for them, then append them to `_comp_specifiers`:\n",
    "        return {k:SpecificComputationValidator.init_from_decorated_fn(v) for k,v in self.registered_merged_computation_function_dict.items() if hasattr(v, 'validate_computation_test') and (v.validate_computation_test is not None)}\n",
    "\n",
    "\n",
    "\n",
    "    def reload_default_computation_functions(self):\n",
    "        \"\"\" reloads/re-registers the default display functions after adding a new one\n",
    "            Note: execution ORDER MATTERS for the computation functions, unlike the display functions, so they need to be enumerated in the correct order and not sorted alphabetically        \n",
    "        # Sort by precidence:\n",
    "            _computationPrecidence\n",
    "        \"\"\"\n",
    "        # Non-Global Items:\n",
    "        for (a_computation_class_name, a_computation_class) in reversed(ComputationFunctionRegistryHolder.get_non_global_registry_items().items()):\n",
    "            for (a_computation_fn_name, a_computation_fn) in reversed(a_computation_class.get_all_functions(use_definition_order=True)):\n",
    "                self.register_computation(a_computation_fn_name, a_computation_fn, is_global=False)\n",
    "        # Global Items:\n",
    "        for (a_computation_class_name, a_computation_class) in reversed(ComputationFunctionRegistryHolder.get_global_registry_items().items()):\n",
    "            for (a_computation_fn_name, a_computation_fn) in reversed(a_computation_class.get_all_functions(use_definition_order=True)):\n",
    "                self.register_computation(a_computation_fn_name, a_computation_fn, is_global=True)\n",
    "\n",
    "    def register_computation(self, registered_name, computation_function, is_global:bool):\n",
    "        # Set the .is_global attribute on the function object itself, since functions are 1st-class objects in Python:\n",
    "        computation_function.is_global = is_global\n",
    "\n",
    "        if is_global:\n",
    "            try:\n",
    "                self.registered_global_computation_function_dict[registered_name] = computation_function\n",
    "            except AttributeError as e:\n",
    "                # Create a new global dictionary if needed and then try re-register:\n",
    "                self.registered_global_computation_function_dict = dict()\n",
    "                self.registered_global_computation_function_dict[registered_name] = computation_function            \n",
    "        else:\n",
    "            # non-global:\n",
    "            try:\n",
    "                self.registered_computation_function_dict[registered_name] = computation_function\n",
    "            except AttributeError as e:\n",
    "                # Create a new non-global dictionary if needed and then try re-register:\n",
    "                self.registered_computation_function_dict = dict()\n",
    "                self.registered_computation_function_dict[registered_name] = computation_function\n",
    "        \n",
    "\n",
    "    def unregister_all_computation_functions(self):\n",
    "        ## Drops all registered computationf functions (global and non-global) so they can be reloaded fresh:\n",
    "        self.registered_global_computation_function_dict = dict()\n",
    "        self.registered_computation_function_dict = dict()\n",
    "\n",
    "\n",
    "    def find_registered_computation_functions(self, registered_names_list, search_mode:FunctionsSearchMode=FunctionsSearchMode.ANY, names_list_is_excludelist:bool=False):\n",
    "        ''' Finds the list of actual function objects associated with the registered_names_list by using the appropriate dictionary of registered functions depending on whether are_global is True or not.\n",
    "\n",
    "        registered_names_list: list<str> - a list of function names to be used to fetch the appropriate functions\n",
    "        are_global: bool - If True, the registered_global_computation_function_dict is used instead of the registered_computation_function_dict\n",
    "        names_list_is_excludelist: bool - if True, registered_names_list is treated as a excludelist, and all functions are returned EXCEPT those that are in registered_names_list\n",
    "\n",
    "        Usage:\n",
    "            active_computation_functions = self.find_registered_computation_functions(computation_functions_name_includelist, are_global=are_global)\n",
    "        '''\n",
    "        # We want to reload the new/modified versions of the functions:\n",
    "        self.reload_default_computation_functions()\n",
    "\n",
    "        if search_mode.name == FunctionsSearchMode.GLOBAL_ONLY.name:\n",
    "            active_registered_computation_function_dict = self.registered_global_computation_function_dict\n",
    "        elif search_mode.name == FunctionsSearchMode.NON_GLOBAL_ONLY.name:\n",
    "            active_registered_computation_function_dict = self.registered_computation_function_dict\n",
    "        elif search_mode.name == FunctionsSearchMode.ANY.name:\n",
    "            # build a merged function dictionary containing both global and non-global functions:\n",
    "            active_registered_computation_function_dict = self.registered_merged_computation_function_dict\n",
    "\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if names_list_is_excludelist:\n",
    "            # excludelist-style operation: treat the registered_names_list as a excludelist and return all registered functions EXCEPT those that are in registered_names_list\n",
    "            active_computation_function_dict = {a_computation_fn_name:a_computation_fn for (a_computation_fn_name, a_computation_fn) in active_registered_computation_function_dict.items() if ((a_computation_fn_name not in registered_names_list) and (getattr(a_computation_fn, 'short_name', a_computation_fn.__name__) not in registered_names_list))}\n",
    "        else:\n",
    "            # default includelist-style operation:\n",
    "            active_computation_function_dict = {a_computation_fn_name:a_computation_fn for (a_computation_fn_name, a_computation_fn) in active_registered_computation_function_dict.items() if ((a_computation_fn_name in registered_names_list) or (getattr(a_computation_fn, 'short_name', a_computation_fn.__name__) in registered_names_list))}\n",
    "\n",
    "        return list(active_computation_function_dict.values())\n",
    "\n",
    "\n",
    "a_man = ComputationFunctionManager()\n",
    "a_man.reload_default_computation_functions()\n",
    "\n",
    "## Specify the computations and the requirements to validate them.\n",
    "\n",
    "## Hardcoded comp_specifiers\n",
    "_comp_specifiers = list(reversed(list(a_man.get_merged_computation_function_validators().values()))) ## Execution order is currently determined by `_comp_specifiers` order and not the order the `include_includelist` lists them (which is good) but the `curr_active_pipeline.registered_merged_computation_function_dict` has them registered in *REVERSE* order for the specific computation function called, so we need to reverse these\n",
    "\n",
    "_comp_specifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the short names of all the possible functions that can be found\n",
    "\n",
    "\n",
    "always_disabled_global_comp_names = ['PBE_stats']\n",
    "always_disabled_non_global_comp_names = ['_perform_specific_epochs_decoding', 'velocity_vs_pf_simplified_count_density', 'placefield_overlap', '_DEP_ratemap_peaks', 'recursive_latent_pf_decoding', 'EloyAnalysis']\n",
    "\n",
    "\n",
    "check_manual_non_global_comp_names = ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'spike_burst_detection', 'extended_stats']\n",
    "check_manual_global_comp_names = ['long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'pf_dt_sequential_surprise', 'long_short_endcap_analysis',\n",
    "                         'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis'] # , 'long_short_rate_remapping'\n",
    "\n",
    "\n",
    "## Get the computation shortnames:\n",
    "non_global_comp_names = [v.short_name for v in  _comp_specifiers if ((not v.is_global) and (v.short_name not in always_disabled_non_global_comp_names))]\n",
    "global_comp_names = [v.short_name for v in  _comp_specifiers if (v.is_global and (v.short_name not in always_disabled_global_comp_names))]\n",
    "\n",
    "non_global_comp_names\n",
    "global_comp_names\n",
    "\n",
    "missing_global_comp_names = list(set(global_comp_names) - set(check_manual_global_comp_names))\n",
    "missing_non_global_comp_names = list(set(non_global_comp_names) - set(check_manual_non_global_comp_names))\n",
    "\n",
    "print(f'missing_global_comp_names: {missing_global_comp_names}')\n",
    "print(f'missing_non_global_comp_names: {missing_non_global_comp_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_print = True\n",
    "force_recompute = False\n",
    "force_recompute_override_computations_includelist = None\n",
    "include_includelist = None\n",
    "\n",
    "dry_run = True\n",
    "include_global_functions = True\n",
    "\n",
    "curr_active_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_comp_specifier_fcn = lambda _comp_specifier, *args, **kwargs: _comp_specifier.try_computation_if_needed(*args, **kwargs)\n",
    "active_comp_specifier_fcn = lambda _comp_specifier, *args, **kwargs: _comp_specifier.try_check_missing_provided_keys(*args, **kwargs)\n",
    "\n",
    "remaining_include_function_names = {k:False for k in include_includelist.copy()}\n",
    "\n",
    "for _comp_specifier in _comp_specifiers:\n",
    "\tif (not _comp_specifier.is_global) or include_global_functions:\n",
    "\t\tif (_comp_specifier.short_name in include_includelist) or (_comp_specifier.computation_fn_name in include_includelist):\n",
    "\t\t\tif (not _comp_specifier.is_global):\n",
    "\t\t\t\t# Not Global-only, need to compute for all `included_computation_filter_names`:\n",
    "\t\t\t\tfor a_computation_filter_name in included_computation_filter_names:\n",
    "\t\t\t\t\tif not dry_run:\n",
    "\t\t\t\t\t\t# newly_computed_values += _comp_specifier.try_computation_if_needed(curr_active_pipeline, computation_filter_name=a_computation_filter_name, on_already_computed_fn=_subfn_on_already_computed, fail_on_exception=fail_on_exception, progress_print=progress_print, debug_print=debug_print, force_recompute=force_recompute)\n",
    "\t\t\t\t\t\tnewly_computed_values += _comp_specifier.try_check_missing_provided_keys(curr_active_pipeline, computation_filter_name=a_computation_filter_name, progress_print=progress_print, force_recompute=force_recompute)\n",
    "\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tprint(f'dry-run: {_comp_specifier.short_name}, computation_filter_name={a_computation_filter_name}, force_recompute={force_recompute}')\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Global-Only:\n",
    "\t\t\t\t_curr_force_recompute = force_recompute or ((_comp_specifier.short_name in force_recompute_override_computations_includelist) or (_comp_specifier.computation_fn_name in force_recompute_override_computations_includelist)) # force_recompute for this specific result if either of its name is included in `force_recompute_override_computations_includelist`\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t# Check for existing result:\n",
    "\t\t\t\tis_known_missing_provided_keys: bool = _comp_specifier.try_check_missing_provided_keys(curr_active_pipeline)\n",
    "\t\t\t\tif is_known_missing_provided_keys:\n",
    "\t\t\t\t\tprint(f'{_comp_specifier.short_name} -- is_known_missing_provided_keys = True!')\n",
    "\n",
    "\t\t\tif (_comp_specifier.short_name in include_includelist):\n",
    "\t\t\t\tdel remaining_include_function_names[_comp_specifier.short_name]\n",
    "\t\t\telif (_comp_specifier.computation_fn_name in include_includelist):\n",
    "\t\t\t\tdel remaining_include_function_names[_comp_specifier.computation_fn_name]\n",
    "\t\t\telse:\n",
    "\t\t\t\traise NotImplementedError\n",
    "\n",
    "if len(remaining_include_function_names) > 0:\n",
    "\tprint(f'WARNING: after execution of all _comp_specifiers found the functions: {remaining_include_function_names} still remain! Are they correct and do they have proper validator decorators?')\n",
    "if progress_print:\n",
    "\tprint('done with all batch_extended_computations(...).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _subfn_on_already_computed(_comp_name, computation_filter_name):\n",
    "\t\"\"\" captures: `progress_print`, `force_recompute`\n",
    "\traises AttributeError if force_recompute is true to trigger recomputation \"\"\"\n",
    "\tif progress_print:\n",
    "\t\tprint(f'{_comp_name}, {computation_filter_name} already computed.')\n",
    "\tif force_recompute:\n",
    "\t\tif progress_print:\n",
    "\t\t\tprint(f'\\tforce_recompute is true so recomputing anyway')\n",
    "\t\traise AttributeError # just raise an AttributeError to trigger recomputation    \n",
    "\n",
    "newly_computed_values = []\n",
    "force_recompute_override_computations_includelist = force_recompute_override_computations_includelist or []\n",
    "\n",
    "non_global_comp_names = ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'spike_burst_detection']\n",
    "global_comp_names = ['long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'pf_dt_sequential_surprise', 'long_short_endcap_analysis',\n",
    "\t\t\t\t\t\t'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis'] # , 'long_short_rate_remapping'\n",
    "\n",
    "# 'firing_rate_trends', 'pf_dt_sequential_surprise'\n",
    "# '_perform_firing_rate_trends_computation', '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "\n",
    "if include_includelist is None:\n",
    "\t# include all:\n",
    "\tinclude_includelist = non_global_comp_names + global_comp_names\n",
    "else:\n",
    "\tprint(f'included includelist is specified: {include_includelist}, so only performing these extended computations.')\n",
    "\n",
    "## Get computed relative entropy measures:\n",
    "_, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# global_epoch_name = curr_active_pipeline.active_completed_computation_result_names[-1] # 'maze'\n",
    "\n",
    "if included_computation_filter_names is None:\n",
    "\tincluded_computation_filter_names = [global_epoch_name] # use only the global epoch: e.g. ['maze']\n",
    "\tif progress_print:\n",
    "\t\tprint(f'Running batch_extended_computations(...) with global_epoch_name: \"{global_epoch_name}\"')\n",
    "else:\n",
    "\tif progress_print:\n",
    "\t\tprint(f'Running batch_extended_computations(...) with included_computation_filter_names: \"{included_computation_filter_names}\"')\n",
    "\n",
    "\n",
    "\n",
    "## Specify the computations and the requirements to validate them.\n",
    "\n",
    "## Hardcoded comp_specifiers\n",
    "_comp_specifiers = list(curr_active_pipeline.get_merged_computation_function_validators().values())\n",
    "## Execution order is currently determined by `_comp_specifiers` order and not the order the `include_includelist` lists them (which is good) but the `curr_active_pipeline.registered_merged_computation_function_dict` has them registered in *REVERSE* order for the specific computation function called, so we need to reverse these\n",
    "_comp_specifiers = reversed(_comp_specifiers)\n",
    "\n",
    "\n",
    "def try_run_compute_comp_specifiers(_comp_specifiers, curr_active_pipeline, include_global_functions: bool = True, ):\n",
    "\t\"\"\" Captures: force_recompute, fail_on_exception, debug_print \n",
    "\t\"\"\"\n",
    "\tremaining_include_function_names = {k:False for k in include_includelist.copy()}\n",
    "\n",
    "\tfor _comp_specifier in _comp_specifiers:\n",
    "\t\tif (not _comp_specifier.is_global) or include_global_functions:\n",
    "\t\t\tif (_comp_specifier.short_name in include_includelist) or (_comp_specifier.computation_fn_name in include_includelist):\n",
    "\t\t\t\tif (not _comp_specifier.is_global):\n",
    "\t\t\t\t\t# Not Global-only, need to compute for all `included_computation_filter_names`:\n",
    "\t\t\t\t\tfor a_computation_filter_name in included_computation_filter_names:\n",
    "\t\t\t\t\t\tif not dry_run:\n",
    "\t\t\t\t\t\t\tnewly_computed_values += _comp_specifier.try_computation_if_needed(curr_active_pipeline, computation_filter_name=a_computation_filter_name, on_already_computed_fn=_subfn_on_already_computed, fail_on_exception=fail_on_exception, progress_print=progress_print, debug_print=debug_print, force_recompute=force_recompute)\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tprint(f'dry-run: {_comp_specifier.short_name}, computation_filter_name={a_computation_filter_name}, force_recompute={force_recompute}')\n",
    "\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# Global-Only:\n",
    "\t\t\t\t\t_curr_force_recompute = force_recompute or ((_comp_specifier.short_name in force_recompute_override_computations_includelist) or (_comp_specifier.computation_fn_name in force_recompute_override_computations_includelist)) # force_recompute for this specific result if either of its name is included in `force_recompute_override_computations_includelist`\n",
    "\t\t\t\t\tif not dry_run:\n",
    "\t\t\t\t\t\tnewly_computed_values += _comp_specifier.try_computation_if_needed(curr_active_pipeline, computation_filter_name=global_epoch_name, on_already_computed_fn=_subfn_on_already_computed, fail_on_exception=fail_on_exception, progress_print=progress_print, debug_print=debug_print, force_recompute=_curr_force_recompute)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tprint(f'dry-run: {_comp_specifier.short_name}, force_recompute={force_recompute}, curr_force_recompute={_curr_force_recompute}')\n",
    "\t\t\t\t\t\t# Check for existing result:\n",
    "\t\t\t\t\t\tis_known_missing_provided_keys: bool = _comp_specifier.try_check_missing_provided_keys(curr_active_pipeline)\n",
    "\t\t\t\t\t\tif is_known_missing_provided_keys:\n",
    "\t\t\t\t\t\t\tprint(f'{_comp_specifier.short_name} -- is_known_missing_provided_keys = True!')\n",
    "\n",
    "\t\t\t\tif (_comp_specifier.short_name in include_includelist):\n",
    "\t\t\t\t\tdel remaining_include_function_names[_comp_specifier.short_name]\n",
    "\t\t\t\telif (_comp_specifier.computation_fn_name in include_includelist):\n",
    "\t\t\t\t\tdel remaining_include_function_names[_comp_specifier.computation_fn_name]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\traise NotImplementedError\n",
    "\n",
    "\treturn remaining_include_function_names\n",
    "\t\n",
    "remaining_include_function_names = try_run_compute_comp_specifiers(_comp_specifiers)\n",
    "\n",
    "if len(remaining_include_function_names) > 0:\n",
    "\tprint(f'WARNING: after execution of all _comp_specifiers found the functions: {remaining_include_function_names} still remain! Are they correct and do they have proper validator decorators?')\n",
    "if progress_print:\n",
    "\tprint('done with all batch_extended_computations(...).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
